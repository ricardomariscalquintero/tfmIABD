version: "3"

services:
  namenode:
    build: ./hadoop
    container_name: namenode
    hostname: namenode
    environment:
      - HDFS_NAMENODE_USER=root
    ports:
      - "9870:9870"   # HDFS Web UI
    networks:
      - hadoop-net
    volumes:
      - namenode_data:/tmp/hadoop
      - /tmp/shared:/shared
    command: >
      bash -c "
        hdfs namenode -format -force &&
        hdfs namenode
      "

  resourcemanager:
    build: ./hadoop
    container_name: resourcemanager
    hostname: resourcemanager
    environment:
      - YARN_RESOURCEMANAGER_USER=root
    ports:
      - "8088:8088"   # YARN Web UI
    networks:
      - hadoop-net
    volumes:
      - /tmp/shared:/shared
    command: >
      bash -c "
        yarn resourcemanager
      "

  datanode1:
    build: ./hadoop
    container_name: datanode1
    hostname: datanode1
    environment:
      - HDFS_DATANODE_USER=root
      - YARN_NODEMANAGER_USER=root
    networks:
      - hadoop-net
    volumes:
      - datanode1_data:/tmp/hadoop
      - /tmp/shared:/shared
    depends_on:
      - namenode
      - resourcemanager
    command: >
      bash -c "
        hdfs datanode &
        yarn nodemanager &
        tail -f /dev/null
      "

  datanode2:
    build: ./hadoop
    container_name: datanode2
    hostname: datanode2
    environment:
      - HDFS_DATANODE_USER=root
      - YARN_NODEMANAGER_USER=root
    networks:
      - hadoop-net
    volumes:
      - datanode2_data:/tmp/hadoop
      - /tmp/shared:/shared
    depends_on:
      - namenode
      - resourcemanager
    command: >
      bash -c "
        hdfs datanode &
        yarn nodemanager &
        tail -f /dev/null
      "

  metastore-db:
    image: mysql:5.7
    container_name: metastore-db
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: metastore
      MYSQL_USER: hive
      MYSQL_PASSWORD: hive
    volumes:
      - metastore_data:/var/lib/mysql
      - /tmp/shared:/shared
    ports:
      - "3306:3306"
    networks:
      - hadoop-net

  hive-server:
    build: ./hadoop-hive
    container_name: hive-server
    hostname: hive-server
    environment:
      HIVE_HOME: /opt/hive
      HADOOP_HOME: /opt/hadoop
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      HIVE_CONF_DIR: /opt/hive/conf
      SERVICE_PRECONDITION: "namenode:9870 metastore-db:3306"
    networks:
      - hadoop-net
    volumes:
      - hive_data:/tmp/hive
      - /tmp/shared:/shared
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - resourcemanager
      - metastore-db
    ports:
      - "10000:10000"   # HiveServer2 (JDBC/Beeline)
      - "9083:9083"     # Hive Metastore (para Thrift)
    command: >
      bash -c "
        dockerize -wait tcp://metastore-db:3306 -timeout 60s &&
        schematool -dbType mysql -initSchema --verbose || echo 'Metastore ya inicializado';
        hive --service metastore &
        hive --service hiveserver2 &
        tail -f /dev/null
      "

  spark-client:
    build: ./spark                    
    container_name: spark-client
    hostname: spark-client
    networks:
      - hadoop-net
    ports:
      - "8888:8888"
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - resourcemanager
      - hive-server
    volumes:
      - /tmp/shared:/shared        
    environment:
      - SPARK_HOME=/opt/spark
      - HADOOP_HOME=/opt/hadoop
      - HIVE_HOME=/opt/hive
      - PATH=/opt/spark/bin:/opt/hadoop/bin:/opt/hive/bin:$PATH
      - SPARK_LOG_LEVEL=ERROR
    tty: true

volumes:
  namenode_data:
  datanode1_data:
  datanode2_data:
  metastore_data:
  hive_data:

networks:
  hadoop-net:


{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e50adc-00c5-4480-aa74-c839e267fbee",
   "metadata": {},
   "source": [
    "# Agrupaci√≥n y limpieza de partidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2adcc5c-86d7-442e-ba46-d0563f461de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-chess\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783a24b4-dc79-4f04-af1c-a04e810b3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes necesarios\n",
    "import chess.pgn\n",
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "#from tqdm import tqdm\n",
    "import subprocess\n",
    "from pyspark.sql import SparkSession\n",
    "from io import StringIO\n",
    "import uuid\n",
    "from multiprocessing import Pool\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e6f81-2db5-4afa-8873-7b7b7a1279c6",
   "metadata": {},
   "source": [
    "## 1. Agrupaci√≥n de partidas por trimestres\n",
    "\n",
    "Esto simplificar√° el n√∫mero de ficheros y lo hace m√°s apto para su almac√©n en HDFS (bloques de 128 Mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63b6225-0669-4726-9b36-02adaed88c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/ajedrez/semestres\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/ajedrez/semestres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23cc7d4-1609-496e-93a3-c79750725802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/09 21:37:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sesi√≥n iniciada en modo: local[*]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"AgruparPartidasLocal\")\n",
    "    .master(\"local[*]\")    ## \"yarn\" es mucho m√°s lento y no necesario (ficheros .pgn muy peque√±os)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(\"Sesi√≥n iniciada en modo:\", sc.master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9927538f-33fe-42c1-b34a-50d68ce5cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Funci√≥n para procesar contenido PGN\n",
    "def procesar_contenido_pgn(contenido):\n",
    "    partidas_por_semestre = defaultdict(list)\n",
    "    f = StringIO(contenido)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            fecha_str = game.headers.get(\"Date\", \"\")\n",
    "            try:\n",
    "                fecha = datetime.strptime(fecha_str, \"%Y.%m.%d\")\n",
    "                anio = fecha.year\n",
    "                mes = fecha.month\n",
    "                semestre = (mes - 1) // 6 + 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            exporter = chess.pgn.StringExporter(headers=True, variations=True, comments=True)\n",
    "            partida_str = game.accept(exporter)\n",
    "            partidas_por_semestre[(anio, semestre)].append(partida_str)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    resultados = []\n",
    "    for (anio, semestre), partidas in partidas_por_semestre.items():\n",
    "        for partida in partidas:\n",
    "            resultados.append(((anio, semestre), partida))\n",
    "    return resultados\n",
    "\n",
    "# Leer archivos PGN desde HDFS\n",
    "rdd = sc.wholeTextFiles(\"hdfs:///user/ajedrez/raw/*.pgn\")\n",
    "\n",
    "# Procesar y agrupar por semestre\n",
    "rdd_partidas = rdd.flatMap(lambda x: procesar_contenido_pgn(x[1]))\n",
    "rdd_agrupado = rdd_partidas.groupByKey().mapValues(list)\n",
    "\n",
    "# Guardar cada grupo como archivo en HDFS\n",
    "def guardar_en_archivo_hdfs(clave_partidas):\n",
    "    (anio, semestre), partidas = clave_partidas\n",
    "    nombre_archivo = f\"/user/ajedrez/semestres/partidas_{anio}_S{semestre}.pgn\"\n",
    "    contenido = \"\\n\\n\".join(partidas)\n",
    "\n",
    "    tmp_path = f\"/tmp/{anio}_S{semestre}.pgn\"\n",
    "    with open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(contenido)\n",
    "\n",
    "    os.system(f\"hdfs dfs -mkdir -p /user/ajedrez/semestres\")\n",
    "    os.system(f\"hdfs dfs -put -f {tmp_path} {nombre_archivo}\")\n",
    "    os.remove(tmp_path)\n",
    "\n",
    "# Ejecutar la escritura\n",
    "rdd_agrupado.foreach(guardar_en_archivo_hdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e186fff-7992-4c5a-a169-5c35c050006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   2 root supergroup    5936129 2025-05-09 21:41 /user/ajedrez/semestres/partidas_2024_S1.pgn\n",
      "-rw-r--r--   2 root supergroup   15201222 2025-05-09 21:41 /user/ajedrez/semestres/partidas_2024_S2.pgn\n",
      "-rw-r--r--   2 root supergroup    5757426 2025-05-09 21:41 /user/ajedrez/semestres/partidas_2025_S1.pgn\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/ajedrez/semestres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4567b-1cd4-4312-be91-5bb71038adc2",
   "metadata": {},
   "source": [
    "## 2. Quitar partidas de 960 (Freechess style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17db28c-1117-4e63-81d4-adb7fc7bfb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Crear sesi√≥n de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FiltrarPGNs\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "spark.stop()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb16d324-a2d1-4620-a603-eadfc95d3556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/user/ajedrez/filtrados': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/ajedrez/filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b08f6d0-dcd3-4e27-b946-a8324065c018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/09 22:22:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "illegal san: 'Nb6' in rnbqkbnr/pppppppp/8/8/5P2/8/PPPPP1PP/RNBQKBNR b KQkq - 0 1 while parsing <Game at 0x7a16ba00f880 ('?' vs. '?', '????.??.??' at '?')>\n",
      "illegal san: 'Nb3' in rnbqkb1r/pp2pp2/2p2np1/2Pp3p/3P3P/6P1/PP2PP2/RNBQKBNR w KQkq - 0 6 while parsing <Game at 0x7a16ba3017f0 ('?' vs. '?', '????.??.??' at '?')>\n",
      "[Stage 1:=============================>                             (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivos filtrados guardados en una sola carpeta HDFS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "import chess.pgn\n",
    "import os\n",
    "\n",
    "# üîπ Crear sesi√≥n Spark\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"FiltrarPartidasNo960\")\n",
    "    .master(\"yarn\")  # Ejecuta los jobs en el cluster Spark-YARN\n",
    "    .getOrCreate()\n",
    ")\n",
    "# üîπ Rutas\n",
    "ruta_entrada = \"hdfs:///user/ajedrez/semestres/*.pgn\"\n",
    "ruta_salida = \"/user/ajedrez/filtrados/\"\n",
    "\n",
    "# üîπ Leer archivos (ruta, contenido)\n",
    "archivos_pgn = sc.wholeTextFiles(ruta_entrada)\n",
    "\n",
    "# üîπ Filtrar partidas v√°lidas\n",
    "def filtrar_partidas(nombre_y_contenido):\n",
    "    ruta_archivo, contenido = nombre_y_contenido\n",
    "    nombre_base = os.path.basename(ruta_archivo)\n",
    "    salida = []\n",
    "\n",
    "    for bloque in contenido.split(\"\\n\\n\"):\n",
    "        bloque = bloque.strip()\n",
    "        if not bloque:\n",
    "            continue\n",
    "        try:\n",
    "            game = chess.pgn.read_game(StringIO(bloque))\n",
    "            if game is None:\n",
    "                continue\n",
    "\n",
    "            # Validar movimientos\n",
    "            board = game.board()\n",
    "            for move in game.mainline_moves():\n",
    "                board.push(move)\n",
    "\n",
    "            variante = game.headers.get(\"Variant\", \"\").lower()\n",
    "            if variante not in [\"chess960\", \"960\"]:\n",
    "                exporter = chess.pgn.StringExporter(headers=True, variations=True, comments=True)\n",
    "                partida_str = game.accept(exporter)\n",
    "                salida.append((nombre_base, partida_str))\n",
    "        except Exception:\n",
    "            continue  # Ignorar errores\n",
    "\n",
    "    return salida\n",
    "\n",
    "# üîπ Aplicar filtrado\n",
    "filtrados = archivos_pgn.flatMap(filtrar_partidas)\n",
    "\n",
    "# üîπ Agrupar y filtrar archivos vac√≠os\n",
    "agrupados = (\n",
    "    filtrados\n",
    "    .groupByKey()\n",
    "    .mapValues(lambda partidas: \"\\n\\n\".join(partidas))\n",
    "    .filter(lambda x: x[1].strip() != \"\")\n",
    ")\n",
    "\n",
    "# üîπ Crear carpeta de salida si no existe\n",
    "os.system(f\"hdfs dfs -mkdir -p {ruta_salida}\")\n",
    "\n",
    "# üîπ Guardar en HDFS\n",
    "def guardar_archivo(nombre_contenido):\n",
    "    nombre, contenido = nombre_contenido\n",
    "    nombre_salida = f\"filtrado_{nombre}\"\n",
    "    ruta_hdfs = os.path.join(ruta_salida, nombre_salida)\n",
    "    ruta_tmp = f\"/tmp/{nombre_salida}\"\n",
    "\n",
    "    with open(ruta_tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(contenido)\n",
    "\n",
    "    os.system(f\"hdfs dfs -rm -f {ruta_hdfs}\")\n",
    "    os.system(f\"hdfs dfs -put -f {ruta_tmp} {ruta_hdfs}\")\n",
    "    os.remove(ruta_tmp)\n",
    "\n",
    "agrupados.foreach(guardar_archivo)\n",
    "\n",
    "print(\"‚úÖ Archivos filtrados guardados en una sola carpeta HDFS.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e055d9c1-e93a-4c7a-ba51-b70419822eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   2 root supergroup    6612589 2025-05-09 22:25 /user/ajedrez/filtrados/filtrado_partidas_2024_S1.pgn\n",
      "-rw-r--r--   2 root supergroup   16935223 2025-05-09 22:25 /user/ajedrez/filtrados/filtrado_partidas_2024_S2.pgn\n",
      "-rw-r--r--   2 root supergroup    6411718 2025-05-09 22:25 /user/ajedrez/filtrados/filtrado_partidas_2025_S1.pgn\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/ajedrez/filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43f094e-fbf9-4677-a711-37cea562e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -get /user/ajedrez/filtrados/*.pgn /shared\n",
    "\n",
    "#Archivos con errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df314a43-6669-4a06-92ea-65970305813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rm /shared/*.pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc88dd20-5856-413c-9271-2538b3ac191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   2 root supergroup    6612591 2025-05-09 21:45 /user/ajedrez/filtrados/filtrado_partidas_2024_S1.pgn\n",
      "-rw-r--r--   2 root supergroup   16935225 2025-05-09 21:45 /user/ajedrez/filtrados/filtrado_partidas_2024_S2.pgn\n",
      "-rw-r--r--   2 root supergroup    6411720 2025-05-09 21:45 /user/ajedrez/filtrados/filtrado_partidas_2025_S1.pgn\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/ajedrez/filtrados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9864b0d1-1e9a-44aa-9248-e03bd2cf22c4",
   "metadata": {},
   "source": [
    "## 3. Eliminaci√≥n de partidas con errores\n",
    "\n",
    "En algunos archivos .pgn, se pueden encontrar partidas incompletas o corruptas, jugadas ilegales (por ejemplo, por errores de edici√≥n), encabezados mal formados, etc. Limpiaremos estas partidas con errores usando `python-chess`, ya que al intentar reproducir las jugadas en un `chess.Board()`, lanza excepciones si hay jugadas inv√°lidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b7c1ed-4f24-40da-a8ed-d7707dd31bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando limpio_filtrado_partidas_2022_3.pgn...\n",
      "Subido: /user/ajedrez/limpios/limpio_filtrado_partidas_2022_3.pgn\n",
      "Guardando limpio_filtrado_partidas_2024_3.pgn...\n",
      "Subido: /user/ajedrez/limpios/limpio_filtrado_partidas_2024_3.pgn\n",
      "Guardando limpio_filtrado_partidas_2023_1.pgn...\n",
      "Subido: /user/ajedrez/limpios/limpio_filtrado_partidas_2023_1.pgn\n",
      "Guardando limpio_filtrado_partidas_2024_1.pgn...\n",
      "Subido: /user/ajedrez/limpios/limpio_filtrado_partidas_2024_1.pgn\n",
      "Guardando limpio_filtrado_partidas_2025_1.pgn...\n",
      "Subido: /user/ajedrez/limpios/limpio_filtrado_partidas_2025_1.pgn\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from io import StringIO\n",
    "import os\n",
    "import chess.pgn\n",
    "import subprocess\n",
    "\n",
    "# Inicializar sesi√≥n Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LimpiarPartidasNoValidas\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Rutas en HDFS\n",
    "ruta_entrada = \"/user/ajedrez/filtrados/\"       \n",
    "ruta_salida = \"/user/ajedrez/limpios/\"\n",
    "\n",
    "# Asegurar carpeta de salida\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-mkdir\", \"-p\", ruta_salida])\n",
    "\n",
    "# Leer archivos .pgn completos desde HDFS\n",
    "archivos_pgn = sc.wholeTextFiles(ruta_entrada + \"*.pgn\")  # (ruta_archivo, contenido)\n",
    "\n",
    "def limpiar_partidas_validas(ruta_y_contenido):\n",
    "    ruta_archivo, contenido = ruta_y_contenido\n",
    "    nombre_archivo = os.path.basename(ruta_archivo)\n",
    "    salida = []\n",
    "\n",
    "    pgn_stream = StringIO(contenido)\n",
    "    while True:\n",
    "        try:\n",
    "            game = chess.pgn.read_game(pgn_stream)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            board = game.board()\n",
    "            try:\n",
    "                for move in game.mainline_moves():\n",
    "                    board.push(move)\n",
    "            except Exception:\n",
    "                continue  # Partida inv√°lida\n",
    "\n",
    "            # Partida v√°lida ‚Üí exportarla\n",
    "            exporter = chess.pgn.StringExporter(headers=True, variations=True, comments=True)\n",
    "            salida.append((nombre_archivo, game.accept(exporter) + \"\\n\\n\"))\n",
    "\n",
    "        except Exception:\n",
    "            continue  # Error cr√≠tico\n",
    "\n",
    "    return salida\n",
    "\n",
    "# Filtrar y agrupar por archivo\n",
    "partidas_limpias = archivos_pgn.flatMap(limpiar_partidas_validas)\n",
    "por_archivo = partidas_limpias.groupByKey().mapValues(lambda partidas: \"\".join(partidas))\n",
    "\n",
    "# Guardar resultados\n",
    "for nombre, contenido in por_archivo.collect():\n",
    "    print(f\"Guardando limpio_{nombre}...\")\n",
    "    nombre_limpio = f\"limpio_{nombre}\"\n",
    "    ruta_local_temp = f\"/tmp/{nombre_limpio}\"\n",
    "    ruta_hdfs = f\"{ruta_salida}{nombre_limpio}\"\n",
    "\n",
    "    with open(ruta_local_temp, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(contenido)\n",
    "\n",
    "    subprocess.run([\"hdfs\", \"dfs\", \"-rm\", ruta_hdfs], stderr=subprocess.DEVNULL)\n",
    "    subprocess.run([\"hdfs\", \"dfs\", \"-put\", ruta_local_temp, ruta_hdfs])\n",
    "    print(f\"Subido: {ruta_hdfs}\")\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bd67e1-573c-4a83-a8c3-de206e2e9f7f",
   "metadata": {},
   "source": [
    "### Sobrante: Funciona pero usa collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b47944-c9cd-4a16-b29f-1c50dd1ff87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Procesando archivo: hdfs://namenode:9000/user/ajedrez/raw/twic1469.pgn\n",
      "‚úÖ A√±adidas 10051 partidas a ./partidas_agrupadas/partidas_2022_3.pgn\n",
      "‚úÖ A√±adidas 576 partidas a ./partidas_agrupadas/partidas_2023_1.pgn\n",
      "üìÇ Procesando archivo: hdfs://namenode:9000/user/ajedrez/raw/twic1535.pgn\n",
      "‚úÖ A√±adidas 6640 partidas a ./partidas_agrupadas/partidas_2024_1.pgn\n",
      "üìÇ Procesando archivo: hdfs://namenode:9000/user/ajedrez/raw/twic1569.pgn\n",
      "‚úÖ A√±adidas 9947 partidas a ./partidas_agrupadas/partidas_2024_3.pgn\n",
      "‚úÖ A√±adidas 35 partidas a ./partidas_agrupadas/partidas_2024_1.pgn\n",
      "üìÇ Procesando archivo: hdfs://namenode:9000/user/ajedrez/raw/twic1589.pgn\n",
      "‚úÖ A√±adidas 10235 partidas a ./partidas_agrupadas/partidas_2025_1.pgn\n",
      "üìÇ Procesando archivo: hdfs://namenode:9000/user/ajedrez/raw/twic1590.pgn\n",
      "‚úÖ A√±adidas 6431 partidas a ./partidas_agrupadas/partidas_2025_1.pgn\n",
      "üìÇ Procesando archivo: hdfs://namenode:9000/user/ajedrez/raw/twic1534.pgn\n",
      "‚úÖ A√±adidas 7971 partidas a ./partidas_agrupadas/partidas_2024_1.pgn\n",
      "‚òÅÔ∏è Subido: ./partidas_agrupadas/partidas_2023_1.pgn ‚Üí /user/ajedrez/cuatrimestres/partidas_2023_1.pgn\n",
      "‚òÅÔ∏è Subido: ./partidas_agrupadas/partidas_2024_3.pgn ‚Üí /user/ajedrez/cuatrimestres/partidas_2024_3.pgn\n",
      "‚òÅÔ∏è Subido: ./partidas_agrupadas/partidas_2025_1.pgn ‚Üí /user/ajedrez/cuatrimestres/partidas_2025_1.pgn\n",
      "‚òÅÔ∏è Subido: ./partidas_agrupadas/partidas_2022_3.pgn ‚Üí /user/ajedrez/cuatrimestres/partidas_2022_3.pgn\n",
      "‚òÅÔ∏è Subido: ./partidas_agrupadas/partidas_2024_1.pgn ‚Üí /user/ajedrez/cuatrimestres/partidas_2024_1.pgn\n",
      "\n",
      "üìä Resumen de partidas por cuatrimestre:\n",
      "üóÇÔ∏è  2022 - Cuatrimestre 3: 10051 partidas\n",
      "üóÇÔ∏è  2023 - Cuatrimestre 1: 576 partidas\n",
      "üóÇÔ∏è  2024 - Cuatrimestre 1: 14646 partidas\n",
      "üóÇÔ∏è  2024 - Cuatrimestre 3: 9947 partidas\n",
      "üóÇÔ∏è  2025 - Cuatrimestre 1: 16666 partidas\n"
     ]
    }
   ],
   "source": [
    "## FUNCIONA\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"AgruparPartidasLocal\")\n",
    "    .master(\"local[*]\")    ## \"yarn\" es mucho m√°s lento y no necesario (ficheros .pgn muy peque√±os)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(\"‚úÖ Sesi√≥n iniciada en modo:\", sc.master)\n",
    "\n",
    "\n",
    "# Crear carpeta local de salida\n",
    "output_dir = \"./partidas_agrupadas\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Leer rutas √∫nicas de archivos PGN en HDFS\n",
    "rdd = sc.wholeTextFiles(\"hdfs:///user/ajedrez/raw/*.pgn\")\n",
    "archivos = rdd.map(lambda x: x[0]).distinct().collect()\n",
    "\n",
    "# Acumulador de resumen\n",
    "resumen_cuatrimestres = defaultdict(int)\n",
    "\n",
    "def procesar_contenido_pgn(contenido):\n",
    "    partidas_por_cuatrimestre = defaultdict(list)\n",
    "    f = StringIO(contenido)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            fecha_str = game.headers.get(\"Date\", \"\")\n",
    "            try:\n",
    "                fecha = datetime.strptime(fecha_str, \"%Y.%m.%d\")\n",
    "                anio = fecha.year\n",
    "                mes = fecha.month\n",
    "                cuatrimestre = (mes - 1) // 4 + 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            exporter = chess.pgn.StringExporter(headers=True, variations=True, comments=True)\n",
    "            partida_str = game.accept(exporter)\n",
    "            partidas_por_cuatrimestre[(anio, cuatrimestre)].append(partida_str)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return partidas_por_cuatrimestre\n",
    "\n",
    "# Procesar cada archivo PGN\n",
    "for ruta in archivos:\n",
    "    print(f\"üìÇ Procesando archivo: {ruta}\")\n",
    "    contenido = rdd.filter(lambda x: x[0] == ruta).collect()[0][1]\n",
    "    agrupadas = procesar_contenido_pgn(contenido)\n",
    "\n",
    "    for (anio, cuatrimestre), partidas in agrupadas.items():\n",
    "        nombre_archivo = f\"partidas_{anio}_{cuatrimestre}.pgn\"\n",
    "        ruta_local = os.path.join(output_dir, nombre_archivo)\n",
    "\n",
    "        with open(ruta_local, \"a\", encoding=\"utf-8\") as f_out:\n",
    "            for partida in partidas:\n",
    "                f_out.write(partida + \"\\n\\n\")\n",
    "\n",
    "        resumen_cuatrimestres[(anio, cuatrimestre)] += len(partidas)\n",
    "        print(f\"‚úÖ A√±adidas {len(partidas)} partidas a {ruta_local}\")\n",
    "\n",
    "# Subir todos los archivos locales generados a HDFS\n",
    "hdfs_destino = \"/user/ajedrez/cuatrimestres\"\n",
    "os.system(f\"hdfs dfs -mkdir -p {hdfs_destino}\")\n",
    "\n",
    "for archivo in os.listdir(output_dir):\n",
    "    if archivo.endswith(\".pgn\"):\n",
    "        ruta_local = os.path.join(output_dir, archivo)\n",
    "        ruta_hdfs = f\"{hdfs_destino}/{archivo}\"\n",
    "        os.system(f\"hdfs dfs -put -f {ruta_local} {ruta_hdfs}\")\n",
    "        print(f\"‚òÅÔ∏è Subido: {ruta_local} ‚Üí {ruta_hdfs}\")\n",
    "\n",
    "# Mostrar resumen final\n",
    "print(\"\\nüìä Resumen de partidas por cuatrimestre:\")\n",
    "for (anio, cuatrimestre), total in sorted(resumen_cuatrimestres.items()):\n",
    "    print(f\"üóÇÔ∏è  {anio} - Cuatrimestre {cuatrimestre}: {total} partidas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b857b-17be-4053-b1ad-c82a85dcae13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

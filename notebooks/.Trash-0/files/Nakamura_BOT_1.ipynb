{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc69900-9fdb-4188-846c-5a649be2149f",
   "metadata": {},
   "source": [
    "## Nueva filosofía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134de9b2-cf56-4ca0-99b8-8ce878bf53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, input_file_name\n",
    "from pyspark.sql.types import StringType\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90933e2-a6d2-4e9c-aebb-d8a92d5b0a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/10 20:17:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Bot_Nakamura\")\n",
    "    .master(\"local[*]\")  # \"yarn\"\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2545dae-23a0-4706-89af-3d63764c28a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - root supergroup          0 2025-05-09 11:46 /user/ajedrez/raw\n"
     ]
    }
   ],
   "source": [
    "# Por si se quiere eliminar alguna carpeta\n",
    "#!hdfs dfs -rm -r /user/ajedrez/jugador\n",
    "# En principio, solo con la carpeta raw y las partidas dentro nos vale\n",
    "!hdfs dfs -ls /user/ajedrez/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b74c2df-3e02-4fd9-a3f1-47ff3a16e59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Leer todos los archivos PGN de HDFS como (ruta, contenido)\n",
    "rdd = spark.sparkContext.wholeTextFiles(\"hdfs:///user/ajedrez/raw/*.pgn\")\n",
    "\n",
    "# Función para dividir cada archivo en partidas individuales\n",
    "def dividir_partidas_por_archivo(nombre_y_contenido):\n",
    "    ruta, contenido = nombre_y_contenido\n",
    "    partidas = re.split(r'\\n(?=\\[Event )', contenido)\n",
    "    return [(ruta, pgn) for pgn in partidas if \"[Event\" in pgn]\n",
    "\n",
    "# Dividir partidas\n",
    "rdd_partidas = rdd.flatMap(dividir_partidas_por_archivo)\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = rdd_partidas.toDF([\"archivo\", \"pgn\"])\n",
    "\n",
    "# UDF para extraer tags PGN\n",
    "def extraer_tag(tag, texto):\n",
    "    match = re.search(rf'\\[{tag} \"([^\"]+)\"\\]', texto)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Registrar UDFs\n",
    "extraer_white = udf(lambda x: extraer_tag(\"White\", x), StringType())\n",
    "extraer_black = udf(lambda x: extraer_tag(\"Black\", x), StringType())\n",
    "extraer_date = udf(lambda x: extraer_tag(\"Date\", x), StringType())\n",
    "\n",
    "# Añadir columnas de metadatos. El Dataframe df tiene todas las partidas\n",
    "df = df.withColumn(\"white\", extraer_white(col(\"pgn\"))) \\\n",
    "       .withColumn(\"black\", extraer_black(col(\"pgn\"))) \\\n",
    "       .withColumn(\"date\", extraer_date(col(\"pgn\")))\n",
    "\n",
    "# Filtrar solo partidas donde juega Nakamura\n",
    "df_nakamura = df.filter((col(\"white\") == \"Nakamura,Hi\") | (col(\"black\") == \"Nakamura,Hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc0cef1d-7d76-470d-b4f7-f37b2744e6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+----------------+----------+\n",
      "|white                          |black           |date      |\n",
      "+-------------------------------+----------------+----------+\n",
      "|Caruana,F                      |Nakamura,Hi     |2024.04.04|\n",
      "|Nakamura,Hi                    |Vidit,S         |2024.04.05|\n",
      "|Abasov,N                       |Nakamura,Hi     |2024.04.06|\n",
      "|Nakamura,Hi                    |Praggnanandhaa,R|2024.04.07|\n",
      "|Perossa,Nicolas                |Nakamura,Hi     |2024.04.02|\n",
      "|Nakamura,Hi                    |Nevednichy,V    |2024.04.02|\n",
      "|Wagner,De                      |Nakamura,Hi     |2024.04.02|\n",
      "|Nakamura,Hi                    |Eljanov,P       |2024.04.02|\n",
      "|Bjerre,Jonas Buhl              |Nakamura,Hi     |2024.04.02|\n",
      "|Nakamura,Hi                    |Kuzubov,Y       |2024.04.02|\n",
      "|Nakamura,Hi                    |Kovalev,Vl      |2024.04.02|\n",
      "|Zemlyanskii,Ivan               |Nakamura,Hi     |2024.04.02|\n",
      "|Nakamura,Hi                    |Duda,J          |2024.04.02|\n",
      "|Kamsky,G                       |Nakamura,Hi     |2024.04.02|\n",
      "|Nakamura,Hi                    |Makarian,Rudik  |2024.04.02|\n",
      "|Sokac,Marko                    |Nakamura,Hi     |2024.04.02|\n",
      "|Nakamura,Hi                    |Richter,Paul    |2024.04.02|\n",
      "|Kushko,Dmitriy                 |Nakamura,Hi     |2024.04.02|\n",
      "|Nakamura,Hi                    |Durarbayli,Vasif|2024.04.02|\n",
      "|Martinez Alcantara,Jose Eduardo|Nakamura,Hi     |2024.04.02|\n",
      "+-------------------------------+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+----------------+----------+\n",
      "|white              |black           |date      |\n",
      "+-------------------+----------------+----------+\n",
      "|Caruana,F          |Nakamura,Hi     |2024.04.04|\n",
      "|Abasov,N           |Nepomniachtchi,I|2024.04.04|\n",
      "|Firouzja,Alireza   |Praggnanandhaa,R|2024.04.04|\n",
      "|Gukesh,D           |Vidit,S         |2024.04.04|\n",
      "|Praggnanandhaa,R   |Gukesh,D        |2024.04.05|\n",
      "|Nakamura,Hi        |Vidit,S         |2024.04.05|\n",
      "|Nepomniachtchi,I   |Firouzja,Alireza|2024.04.05|\n",
      "|Caruana,F          |Abasov,N        |2024.04.05|\n",
      "|Gukesh,D           |Nepomniachtchi,I|2024.04.06|\n",
      "|Abasov,N           |Nakamura,Hi     |2024.04.06|\n",
      "|Firouzja,Alireza   |Caruana,F       |2024.04.06|\n",
      "|Vidit,S            |Praggnanandhaa,R|2024.04.06|\n",
      "|Nakamura,Hi        |Praggnanandhaa,R|2024.04.07|\n",
      "|Nepomniachtchi,I   |Vidit,S         |2024.04.07|\n",
      "|Caruana,F          |Gukesh,D        |2024.04.07|\n",
      "|Abasov,N           |Firouzja,Alireza|2024.04.07|\n",
      "|Goryachkina,A      |Lagno,Kateryna  |2024.04.04|\n",
      "|Muzychuk,A         |Salimova,Nurgyul|2024.04.04|\n",
      "|Lei,Tingjie        |Tan,Zhongyi     |2024.04.04|\n",
      "|Vaishali,Rameshbabu|Koneru,H        |2024.04.04|\n",
      "+-------------------+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/10 20:18:02 WARN BlockReaderFactory: I/O error constructing remote block reader.\n",
      "java.nio.channels.ClosedByInterruptException\n",
      "\tat java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:658)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:191)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3033)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:829)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:754)\n",
      "\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:381)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:755)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:685)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:884)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:957)\n",
      "\tat java.io.DataInputStream.read(DataInputStream.java:100)\n",
      "\tat org.sparkproject.guava.io.ByteStreams.copy(ByteStreams.java:207)\n",
      "\tat org.sparkproject.guava.io.ByteStreams.toByteArray(ByteStreams.java:252)\n",
      "\tat org.apache.spark.input.WholeTextFileRecordReader.nextKeyValue(WholeTextFileRecordReader.scala:79)\n",
      "\tat org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.nextKeyValue(CombineFileRecordReader.java:65)\n",
      "\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:254)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:322)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:751)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:451)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:282)\n"
     ]
    }
   ],
   "source": [
    "# Dataframe de Nakamura y Dataframe de todas las partidas\n",
    "df_nakamura.select(\"white\", \"black\", \"date\").show(truncate=False)\n",
    "df.select(\"white\", \"black\", \"date\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f639b90-2fb8-4108-9498-be9cf0d7524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (70, 5)\n",
      "['archivo', 'pgn', 'white', 'black', 'date']\n",
      "Shape: (30216, 5)\n",
      "['archivo', 'pgn', 'white', 'black', 'date']\n"
     ]
    }
   ],
   "source": [
    "filas = df_nakamura.count()\n",
    "columnas = len(df_nakamura.columns)\n",
    "print(f\"Shape: ({filas}, {columnas})\")\n",
    "print(df_nakamura.columns)\n",
    "\n",
    "filas = df.count()\n",
    "columnas = len(df.columns)\n",
    "print(f\"Shape: ({filas}, {columnas})\")\n",
    "print(df.columns)\n",
    "\n",
    "# Nombre del archivo donde está la partida (twicXXXX.pgn) , partida en pgn, jugador que jugó con blancas / negras y fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f73fc26c-2342-47e8-a7f1-5b68468c9e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Event \"FIDE Candidates 2024\"]\n",
      "[Site \"Toronto CAN\"]\n",
      "[Date \"2024.04.04\"]\n",
      "[Round \"1.1\"]\n",
      "[White \"Caruana,F\"]\n",
      "[Black \"Nakamura,Hi\"]\n",
      "[Result \"1/2-1/2\"]\n",
      "[WhiteTitle \"GM\"]\n",
      "[BlackTitle \"GM\"]\n",
      "[WhiteElo \"2803\"]\n",
      "[BlackElo \"2789\"]\n",
      "[ECO \"B56\"]\n",
      "[Opening \"Sicilian\"]\n",
      "[Variation \"Venice attack\"]\n",
      "[WhiteFideId \"2020009\"]\n",
      "[BlackFideId \"2016192\"]\n",
      "[EventDate \"2024.04.04\"]\n",
      "\n",
      "1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e5 6. Bb5+ Nbd7 7. Nf5 a6 8.\n",
      "Ba4 b5 9. Bb3 Nc5 10. Bg5 Bxf5 11. exf5 Be7 12. Bxf6 Bxf6 13. O-O e4 14. Nxe4\n",
      "Nxe4 15. Re1 O-O 16. Rxe4 Bxb2 17. Rb1 Bf6 18. Qd5 Rc8 19. Qb7 Rc5 20. Qxa6 Rxf5\n",
      "21. Rd1 d5 22. Rb4 Bc3 23. Rxb5 Rxf2 24. Rbxd5 Qh4 25. Qd3 Rf6 26. g3 Qb4 27.\n",
      "Kg2 Bb2 28. Rf5 g6 29. Rxf6 Bxf6 30. Qf3 Qe7 31. a4 Kg7 32. a5 Ra8 33. Rd5 Ra7\n",
      "34. Rb5 Qd8 35. Rd5 Qc7 36. h4 Rxa5 37. Rxa5 Qxa5 38. Qb7 Qd8 39. Qxf7+ Kh6 40.\n",
      "Kh3 Qe7 41. Qc4 Qe3 1/2-1/2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Primera partida del dataframe global\n",
    "print(df.select(\"pgn\").first()[\"pgn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25554bf2-ef29-4f77-a94f-b01f95b3b53a",
   "metadata": {},
   "source": [
    "### Notación FEN previa + movimiento + color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "174ff74c-e519-4a9b-9508-196de716852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+----+-----+\n",
      "|FEN                                                                |Move|Color|\n",
      "+-------------------------------------------------------------------+----+-----+\n",
      "|rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1         |c7c5|black|\n",
      "|rnbqkbnr/pp1ppppp/8/2p5/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2     |d7d6|black|\n",
      "|rnbqkbnr/pp2pppp/3p4/2p5/3PP3/5N2/PPP2PPP/RNBQKB1R b KQkq - 0 3    |c5d4|black|\n",
      "|rnbqkbnr/pp2pppp/3p4/8/3NP3/8/PPP2PPP/RNBQKB1R b KQkq - 0 4        |g8f6|black|\n",
      "|rnbqkb1r/pp2pppp/3p1n2/8/3NP3/2N5/PPP2PPP/R1BQKB1R b KQkq - 2 5    |e7e5|black|\n",
      "|rnbqkb1r/pp3ppp/3p1n2/1B2p3/3NP3/2N5/PPP2PPP/R1BQK2R b KQkq - 1 6  |b8d7|black|\n",
      "|r1bqkb1r/pp1n1ppp/3p1n2/1B2pN2/4P3/2N5/PPP2PPP/R1BQK2R b KQkq - 3 7|a7a6|black|\n",
      "|r1bqkb1r/1p1n1ppp/p2p1n2/4pN2/B3P3/2N5/PPP2PPP/R1BQK2R b KQkq - 1 8|b7b5|black|\n",
      "|r1bqkb1r/3n1ppp/p2p1n2/1p2pN2/4P3/1BN5/PPP2PPP/R1BQK2R b KQkq - 1 9|d7c5|black|\n",
      "|r1bqkb1r/5ppp/p2p1n2/1pn1pNB1/4P3/1BN5/PPP2PPP/R2QK2R b KQkq - 3 10|c8f5|black|\n",
      "|r2qkb1r/5ppp/p2p1n2/1pn1pPB1/8/1BN5/PPP2PPP/R2QK2R b KQkq - 0 11   |f8e7|black|\n",
      "|r2qk2r/4bppp/p2p1B2/1pn1pP2/8/1BN5/PPP2PPP/R2QK2R b KQkq - 0 12    |e7f6|black|\n",
      "|r2qk2r/5ppp/p2p1b2/1pn1pP2/8/1BN5/PPP2PPP/R2Q1RK1 b kq - 1 13      |e5e4|black|\n",
      "|r2qk2r/5ppp/p2p1b2/1pn2P2/4N3/1B6/PPP2PPP/R2Q1RK1 b kq - 0 14      |c5e4|black|\n",
      "|r2qk2r/5ppp/p2p1b2/1p3P2/4n3/1B6/PPP2PPP/R2QR1K1 b kq - 1 15       |e8g8|black|\n",
      "|r2q1rk1/5ppp/p2p1b2/1p3P2/4R3/1B6/PPP2PPP/R2Q2K1 b - - 0 16        |f6b2|black|\n",
      "|r2q1rk1/5ppp/p2p4/1p3P2/4R3/1B6/PbP2PPP/1R1Q2K1 b - - 1 17         |b2f6|black|\n",
      "|r2q1rk1/5ppp/p2p1b2/1p1Q1P2/4R3/1B6/P1P2PPP/1R4K1 b - - 3 18       |a8c8|black|\n",
      "|2rq1rk1/1Q3ppp/p2p1b2/1p3P2/4R3/1B6/P1P2PPP/1R4K1 b - - 5 19       |c8c5|black|\n",
      "|3q1rk1/5ppp/Q2p1b2/1pr2P2/4R3/1B6/P1P2PPP/1R4K1 b - - 0 20         |c5f5|black|\n",
      "+-------------------------------------------------------------------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, explode, col\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, StringType\n",
    "import chess.pgn\n",
    "import io\n",
    "\n",
    "# Función para extraer las jugadas que hizo Nakamura (sin importar color)\n",
    "def pgn_a_jugadas_nakamura(pgn_str):\n",
    "    resultado = []\n",
    "    try:\n",
    "        game = chess.pgn.read_game(io.StringIO(pgn_str))\n",
    "        if not game:\n",
    "            return []\n",
    "\n",
    "        board = game.board()\n",
    "        white = game.headers.get(\"White\", \"\")\n",
    "        black = game.headers.get(\"Black\", \"\")\n",
    "\n",
    "        if white == \"Nakamura,Hi\":\n",
    "            color_jugador = chess.WHITE\n",
    "            color = \"white\"\n",
    "        elif black == \"Nakamura,Hi\":\n",
    "            color_jugador = chess.BLACK\n",
    "            color = \"black\"\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        for move in game.mainline_moves():\n",
    "            if board.turn == color_jugador:\n",
    "                resultado.append((board.fen(), move.uci(), color))\n",
    "            board.push(move)\n",
    "    except:\n",
    "        pass\n",
    "    return resultado\n",
    "\n",
    "# Esquema de salida\n",
    "esquema_jugada = ArrayType(StructType([\n",
    "    StructField(\"FEN\", StringType(), True),\n",
    "    StructField(\"Move\", StringType(), True),\n",
    "    StructField(\"Color\", StringType(), True)\n",
    "]))\n",
    "\n",
    "# UDF para extraer jugadas del jugador\n",
    "pgn_udf_nakamura = udf(pgn_a_jugadas_nakamura, esquema_jugada)\n",
    "\n",
    "# Aplicar y explotar resultados\n",
    "df_jugadas = df_nakamura.withColumn(\"jugadas\", explode(pgn_udf_nakamura(col(\"pgn\")))) \\\n",
    "                        .select(col(\"jugadas.FEN\"), col(\"jugadas.Move\"), col(\"jugadas.Color\"))\n",
    "\n",
    "# Cachear y mostrar\n",
    "df_jugadas.cache()\n",
    "df_jugadas.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6137542-31dc-4649-9e88-add43a38f4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Color|count|\n",
      "+-----+-----+\n",
      "|white| 1420|\n",
      "|black| 1779|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Están las jugadas realizadas en ambos colores\n",
    "df_jugadas.groupBy(\"Color\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63dce12-7265-4f6e-8f8c-3f82e3910c2d",
   "metadata": {},
   "source": [
    "⚠️ Consideraciones clave para adaptar tu flujo a Spark MLlib:\n",
    "MLlib no soporta tensores 3D (8x8x12) directamente.\n",
    "\n",
    "MLlib trabaja con Vector (denso o disperso), por lo tanto debes aplanar tu tensor a un vector de tamaño 8×8×12 = 768.\n",
    "\n",
    "No hay soporte nativo para LabelEncoder de sklearn, pero puedes hacer lo mismo con StringIndexer de Spark.\n",
    "\n",
    "UDFs con NumPy son posibles, pero deben devolver estructuras planas (List[Float]), no arrays 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36090948-27d5-4767-a275-63b1be5f36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# UDF para convertir FEN a vector\n",
    "piece_to_plane = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}\n",
    "\n",
    "def fen_to_vector(fen):\n",
    "    tensor = np.zeros((8, 8, 12), dtype=np.float32)\n",
    "    fen_board = fen.split(' ')[0]\n",
    "    rows = fen_board.split('/')\n",
    "    for i, row in enumerate(rows):\n",
    "        col_idx = 0\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                col_idx += int(char)\n",
    "            elif char in piece_to_plane:\n",
    "                plane = piece_to_plane[char]\n",
    "                tensor[i, col_idx, plane] = 1\n",
    "                col_idx += 1\n",
    "    return tensor.flatten().tolist()\n",
    "\n",
    "# Registrar UDF\n",
    "fen_udf = udf(fen_to_vector, ArrayType(FloatType()))\n",
    "\n",
    "# Aplicar la UDF\n",
    "df_feat = df_jugadas.withColumn(\"features\", fen_udf(col(\"FEN\")))\n",
    "\n",
    "# Separar por color\n",
    "df_white = df_feat.filter(col(\"Color\") == \"white\")\n",
    "df_black = df_feat.filter(col(\"Color\") == \"black\")\n",
    "\n",
    "# Ajustar los indexadores\n",
    "indexer_white = StringIndexer(inputCol=\"Move\", outputCol=\"label\")\n",
    "model_white = indexer_white.fit(df_white)\n",
    "df_white_indexed = model_white.transform(df_white).select(\"features\", \"label\")\n",
    "\n",
    "indexer_black = StringIndexer(inputCol=\"Move\", outputCol=\"label\")\n",
    "model_black = indexer_black.fit(df_black)\n",
    "df_black_indexed = model_black.transform(df_black).select(\"features\", \"label\")\n",
    "\n",
    "# Guardar las clases (etiquetas)\n",
    "np.save(\"encoder_blancas.npy\", model_white.labels)\n",
    "np.save(\"encoder_negras.npy\", model_black.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3170514-6e76-4285-a8a3-7155bda1bc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.0, 0.0, 0.0, 0...| 19.0|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.0, 0.0, 0.0, 0...|  7.0|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_white_indexed.printSchema()\n",
    "df_white_indexed.show(1)\n",
    "df_black_indexed.printSchema()\n",
    "df_black_indexed.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046d0a3-eb22-4eba-8744-e04d9995f06c",
   "metadata": {},
   "source": [
    "Lo que puedes hacer en entorno distribuido con Spark MLlib:\n",
    "MLlib no soporta CNNs ni tensores 4D. Su diseño está enfocado a:\n",
    "\n",
    "Modelos clásicos: árboles, regresión, SVM, redes densas básicas.\n",
    "\n",
    "Operación sobre vectores 1D (features) y etiquetas (label).\n",
    "\n",
    "Entrenamiento distribuido y escalable, pero no deep learning como en Keras.\n",
    "\n",
    "2. Alternativas si necesitas CNN en un entorno distribuido\n",
    "Aunque MLlib no soporta CNN, puedes usar frameworks especializados en deep learning que sí funcionan en entornos distribuidos:\n",
    "\n",
    "a) TensorFlow o PyTorch con Horovod o Spark\n",
    "Puedes integrar TensorFlow o PyTorch con Horovod, que permite entrenamiento distribuido sobre múltiples nodos.\n",
    "\n",
    "También puedes usar TensorFlowOnSpark o BigDL (una biblioteca de deep learning optimizada para Spark) para ejecutar redes neuronales sobre clústeres.\n",
    "\n",
    "b) BigDL\n",
    "BigDL es una alternativa poderosa si ya estás usando Spark y quieres hacer deep learning directamente sobre ese ecosistema.\n",
    "\n",
    "Soporta CNN, RNN y otros modelos complejos, y permite entrenamiento distribuido.\n",
    "\n",
    "Conclusión\n",
    "MLlib no es adecuado para CNN, pero puedes usar herramientas externas como TensorFlow + Horovod, BigDL o TensorFlowOnSpark si necesitas entrenamiento distribuido de redes neuronales profundas.\n",
    "\n",
    "⚠️ Limitación clave: Spark ≠ TensorFlow\n",
    "Spark y TensorFlow usan entornos de ejecución diferentes:\n",
    "\n",
    "Spark distribuye y mantiene df_final en su propio contexto de ejecución (con sus RDDs y DAGs).\n",
    "\n",
    "TensorFlow o Keras necesita los datos en forma de NumPy o Tensor en memoria local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45011c0a-e100-416f-a55b-ebd452bce94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar DataFrame como Parquet en volumen compartido\n",
    "# df_final.write.mode(\"overwrite\").parquet(\"/shared/fen_jugadas.parquet\")   NO FUNCIONA\n",
    "import os\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "os.makedirs(\"/notebooks/datos_cnn/blancas\", exist_ok=True)\n",
    "os.makedirs(\"/notebooks/datos_cnn/negras\", exist_ok=True)\n",
    "\n",
    "# Guardar en parquet\n",
    "df_white_pandas = df_white_indexed.toPandas()\n",
    "df_black_pandas = df_black_indexed.toPandas()\n",
    "\n",
    "df_white_pandas.to_parquet(\"/notebooks/datos_cnn/blancas/fen_jugadas.parquet\", index=False)\n",
    "df_black_pandas.to_parquet(\"/notebooks/datos_cnn/negras/fen_jugadas.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43632be5-29c8-4db8-9af4-25a05632ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 40\n",
      "-rw-r--r-- 1 root root 40189 May 10 20:22 fen_jugadas.parquet\n",
      "total 48\n",
      "-rw-r--r-- 1 root root 46712 May 10 20:22 fen_jugadas.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -l /notebooks/datos_cnn/blancas\n",
    "!ls -l /notebooks/datos_cnn/negras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d1598c-f5d2-4a01-a761-3d047e2f390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]"
     ]
    }
   ],
   "source": [
    "# Creamos una función de entrenamiento para reutilizarla tanto en blancas como en negras\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"To exit: use 'exit', 'quit', or Ctrl-D.\")\n",
    "\n",
    "def entrenar_cnn_distribuida(data_path, model_path):\n",
    "    from tensorflowonspark import TFCluster, TFNode\n",
    "    import tensorflow as tf\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    def model_fn(num_classes):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape=(8, 8, 12)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def main_fun(args, ctx):\n",
    "        df = pd.read_parquet(args[\"data_path\"])\n",
    "        X = np.array(df[\"features\"].tolist()).reshape(-1, 8, 8, 12)\n",
    "        y = df[\"label\"].astype(np.int32).values\n",
    "\n",
    "        num_classes = len(np.unique(y))  # ✅ ahora correctamente antes de usar\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "        model = model_fn(num_classes)\n",
    "        model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), batch_size=32)\n",
    "\n",
    "        if ctx.job_name == \"chief\":\n",
    "            model.save(args[\"model_path\"])\n",
    "\n",
    "    # Crear SparkCluster y lanzar\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark = SparkSession.builder.appName(\"TFoS-CNN\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "\n",
    "    args = {\"data_path\": data_path, \"model_path\": model_path}\n",
    "    cluster = TFCluster.run(sc, main_fun, args, num_executors=2, num_ps=1,\n",
    "                            input_mode=TFCluster.InputMode.TENSORFLOW,\n",
    "                            master_node=\"chief\", log_dir=\"/tmp/tf_logs\")\n",
    "    # cluster.shutdown()  # solo si usas fuera de notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "478ac634-f25a-4246-995d-0bc0221d0b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 20:22:10.230176: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:22:10.275533: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:22:10.276119: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-10 20:22:11.048934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "25/05/10 20:22:12 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "2025-05-10 20:22:12.598739: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:22:12.598739: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:22:12.649231: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:22:12.649724: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-10 20:22:12.649795: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:22:12.651013: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-10 20:22:13.816103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-10 20:22:13.826201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-10 20:22:15,336 INFO (MainThread-3018) connected to server at ('172.18.0.10', 39833)\n",
      "2025-05-10 20:22:15,336 INFO (MainThread-3018) TFSparkNode.reserve: {'executor_id': 1, 'host': '172.18.0.10', 'job_name': 'chief', 'task_index': 0, 'port': 38445, 'tb_pid': 0, 'tb_port': 0, 'addr': '/tmp/pymp-xte_tsya/listener-92pjs22v', 'authkey': b'\\xff\\x11\\x8f\\x1e\\x88\\x99K\\xa1\\xa6\\xc7~5\\x1d#\\xfc\\xa1'}\n",
      "2025-05-10 20:22:15,578 INFO (MainThread-3022) connected to server at ('172.18.0.10', 39833)\n",
      "2025-05-10 20:22:15,579 INFO (MainThread-3022) TFSparkNode.reserve: {'executor_id': 0, 'host': '172.18.0.10', 'job_name': 'ps', 'task_index': 0, 'port': 35001, 'tb_pid': 0, 'tb_port': 0, 'addr': ('172.18.0.10', 44819), 'authkey': b'\\x93\\x91#\\xc5\\xa2\\x97K\\x84\\xae\\xd9O\\x9f\\xf5\\xfe\\x88\\x95'}\n",
      "2025-05-10 20:22:16,581 INFO (MainThread-3022) node: {'executor_id': 0, 'host': '172.18.0.10', 'job_name': 'ps', 'task_index': 0, 'port': 35001, 'tb_pid': 0, 'tb_port': 0, 'addr': ('172.18.0.10', 44819), 'authkey': b'\\x93\\x91#\\xc5\\xa2\\x97K\\x84\\xae\\xd9O\\x9f\\xf5\\xfe\\x88\\x95'}\n",
      "2025-05-10 20:22:16,582 INFO (MainThread-3022) node: {'executor_id': 1, 'host': '172.18.0.10', 'job_name': 'chief', 'task_index': 0, 'port': 38445, 'tb_pid': 0, 'tb_port': 0, 'addr': '/tmp/pymp-xte_tsya/listener-92pjs22v', 'authkey': b'\\xff\\x11\\x8f\\x1e\\x88\\x99K\\xa1\\xa6\\xc7~5\\x1d#\\xfc\\xa1'}\n",
      "2025-05-10 20:22:16,582 INFO (MainThread-3022) export TF_CONFIG: {\"cluster\": {\"ps\": [\"172.18.0.10:35001\"], \"chief\": [\"172.18.0.10:38445\"]}, \"task\": {\"type\": \"ps\", \"index\": 0}, \"environment\": \"cloud\"}\n",
      "2025-05-10 20:22:16,598 INFO (MainThread-3022) Starting TensorFlow ps:0 as ps on cluster node 0 on background process\n",
      "Epoch 1/5\n",
      "2025-05-10 20:22:17,340 INFO (MainThread-3018) node: {'executor_id': 0, 'host': '172.18.0.10', 'job_name': 'ps', 'task_index': 0, 'port': 35001, 'tb_pid': 0, 'tb_port': 0, 'addr': ('172.18.0.10', 44819), 'authkey': b'\\x93\\x91#\\xc5\\xa2\\x97K\\x84\\xae\\xd9O\\x9f\\xf5\\xfe\\x88\\x95'}\n",
      "2025-05-10 20:22:17,341 INFO (MainThread-3018) node: {'executor_id': 1, 'host': '172.18.0.10', 'job_name': 'chief', 'task_index': 0, 'port': 38445, 'tb_pid': 0, 'tb_port': 0, 'addr': '/tmp/pymp-xte_tsya/listener-92pjs22v', 'authkey': b'\\xff\\x11\\x8f\\x1e\\x88\\x99K\\xa1\\xa6\\xc7~5\\x1d#\\xfc\\xa1'}\n",
      "2025-05-10 20:22:17,341 INFO (MainThread-3018) export TF_CONFIG: {\"cluster\": {\"ps\": [\"172.18.0.10:35001\"], \"chief\": [\"172.18.0.10:38445\"]}, \"task\": {\"type\": \"chief\", \"index\": 0}, \"environment\": \"cloud\"}\n",
      "2025-05-10 20:22:17,356 INFO (MainThread-3018) Starting TensorFlow chief:0 on cluster node 1 on foreground thread\n",
      "17/40 [===========>..................] - ETA: 0s - loss: 6.2151 - accuracy: 0.0092Epoch 1/5\n",
      "40/40 [==============================] - 1s 15ms/step - loss: 6.1361 - accuracy: 0.0110 - val_loss: 5.8086 - val_accuracy: 0.0141\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.7009 - accuracy: 0.0156 - val_loss: 5.6200 - val_accuracy: 0.0282\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.5919 - accuracy: 0.0219 - val_loss: 5.6968 - val_accuracy: 0.0282\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 5.5003 - accuracy: 0.0282 - val_loss: 5.6647 - val_accuracy: 0.0423\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 2s 26ms/step - loss: 6.1249 - accuracy: 0.0149 - val_loss: 5.8005 - val_accuracy: 0.0141\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 5.4336 - accuracy: 0.0313 - val_loss: 5.7899 - val_accuracy: 0.0493\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 5.7110 - accuracy: 0.0196 - val_loss: 5.6202 - val_accuracy: 0.0211\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.5709 - accuracy: 0.0305 - val_loss: 5.6704 - val_accuracy: 0.0352\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 5.4772 - accuracy: 0.0290 - val_loss: 5.6952 - val_accuracy: 0.0493\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 5.3998 - accuracy: 0.0415 - val_loss: 5.7232 - val_accuracy: 0.0423\n",
      "INFO:tensorflow:Assets written to: /notebooks/datos_cnn/modelo_blancas/assets\n",
      "2025-05-10 20:22:22,392 INFO (MainThread-3018) Assets written to: /notebooks/datos_cnn/modelo_blancas/assets\n",
      "2025-05-10 20:22:22,410 INFO (MainThread-3018) Finished TensorFlow chief:0 on cluster node 1\n",
      "[Stage 29:=============================>                            (1 + 1) / 2]"
     ]
    }
   ],
   "source": [
    "# Modelo para blancas\n",
    "entrenar_cnn_distribuida(\n",
    "    data_path=\"/notebooks/datos_cnn/blancas/fen_jugadas.parquet\",\n",
    "    model_path=\"/notebooks/datos_cnn/modelo_blancas\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0368139-0f48-45a8-a4df-2fa7635cc4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANTE: REINICIAR EL KERNEL\n",
    "## Ejecutar la celda de la función \"entrenar_cnn_distribuida\" y luego la siguiente, el modelo para negras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0612fb40-2ea0-4deb-906d-101216cc7c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 20:22:54.604818: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:22:54.660421: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:22:54.661592: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-10 20:22:55.517739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/10 20:22:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2025-05-10 20:23:00,707 INFO (MainThread-3313) Reserving TFSparkNodes \n",
      "2025-05-10 20:23:00,708 INFO (MainThread-3313) cluster_template: {'ps': [0], 'chief': [1]}\n",
      "2025-05-10 20:23:00,714 INFO (MainThread-3313) Reservation server binding to port 0\n",
      "2025-05-10 20:23:00,716 INFO (MainThread-3313) listening for reservations at ('172.18.0.10', 41539)\n",
      "2025-05-10 20:23:00,717 INFO (MainThread-3313) Starting TensorFlow on executors\n",
      "2025-05-10 20:23:00,967 INFO (MainThread-3313) Waiting for TFSparkNodes to start\n",
      "2025-05-10 20:23:00,968 INFO (MainThread-3313) waiting for 2 reservations\n",
      "2025-05-10 20:23:01,970 INFO (MainThread-3313) waiting for 2 reservations2) / 2]\n",
      "2025-05-10 20:23:02.581316: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:23:02.581316: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:23:02.629960: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:23:02.630675: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-10 20:23:02.630771: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-10 20:23:02.631100: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-10 20:23:02,971 INFO (MainThread-3313) waiting for 2 reservations\n",
      "2025-05-10 20:23:03.593298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-10 20:23:03.594371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-10 20:23:03,974 INFO (MainThread-3313) waiting for 2 reservations\n",
      "2025-05-10 20:23:04,976 INFO (MainThread-3313) waiting for 2 reservations\n",
      "2025-05-10 20:23:05,702 INFO (MainThread-3484) connected to server at ('172.18.0.10', 41539)\n",
      "2025-05-10 20:23:05,719 INFO (MainThread-3484) TFSparkNode.reserve: {'executor_id': 1, 'host': '172.18.0.10', 'job_name': 'chief', 'task_index': 0, 'port': 46731, 'tb_pid': 0, 'tb_port': 0, 'addr': '/tmp/pymp-9io_fq71/listener-suqag89r', 'authkey': b'\\xff\\xbe\\xb5Y\\x95CE\\x94\\xbb\\x8a\\xda\\x9b\\xa6\\x06\\xd3\\xaf'}\n",
      "2025-05-10 20:23:05,899 INFO (MainThread-3485) connected to server at ('172.18.0.10', 41539)\n",
      "2025-05-10 20:23:05,900 INFO (MainThread-3485) TFSparkNode.reserve: {'executor_id': 0, 'host': '172.18.0.10', 'job_name': 'ps', 'task_index': 0, 'port': 42459, 'tb_pid': 0, 'tb_port': 0, 'addr': ('172.18.0.10', 33969), 'authkey': b'\\x14\\xde\\xfe\\x13\\xd1(Lk\\x82C\\xa9\\x1e\\x07\\xecu\\xb3'}\n",
      "2025-05-10 20:23:05,978 INFO (MainThread-3313) all reservations completed\n",
      "2025-05-10 20:23:05,979 INFO (MainThread-3313) All TFSparkNodes started\n",
      "2025-05-10 20:23:05,980 INFO (MainThread-3313) {'executor_id': 1, 'host': '172.18.0.10', 'job_name': 'chief', 'task_index': 0, 'port': 46731, 'tb_pid': 0, 'tb_port': 0, 'addr': '/tmp/pymp-9io_fq71/listener-suqag89r', 'authkey': b'\\xff\\xbe\\xb5Y\\x95CE\\x94\\xbb\\x8a\\xda\\x9b\\xa6\\x06\\xd3\\xaf'}\n",
      "2025-05-10 20:23:05,982 INFO (MainThread-3313) {'executor_id': 0, 'host': '172.18.0.10', 'job_name': 'ps', 'task_index': 0, 'port': 42459, 'tb_pid': 0, 'tb_port': 0, 'addr': ('172.18.0.10', 33969), 'authkey': b'\\x14\\xde\\xfe\\x13\\xd1(Lk\\x82C\\xa9\\x1e\\x07\\xecu\\xb3'}\n",
      "2025-05-10 20:23:06,902 INFO (MainThread-3485) node: {'executor_id': 0, 'host': '172.18.0.10', 'job_name': 'ps', 'task_index': 0, 'port': 42459, 'tb_pid': 0, 'tb_port': 0, 'addr': ('172.18.0.10', 33969), 'authkey': b'\\x14\\xde\\xfe\\x13\\xd1(Lk\\x82C\\xa9\\x1e\\x07\\xecu\\xb3'}\n",
      "2025-05-10 20:23:06,903 INFO (MainThread-3485) node: {'executor_id': 1, 'host': '172.18.0.10', 'job_name': 'chief', 'task_index': 0, 'port': 46731, 'tb_pid': 0, 'tb_port': 0, 'addr': '/tmp/pymp-9io_fq71/listener-suqag89r', 'authkey': b'\\xff\\xbe\\xb5Y\\x95CE\\x94\\xbb\\x8a\\xda\\x9b\\xa6\\x06\\xd3\\xaf'}\n",
      "2025-05-10 20:23:06,903 INFO (MainThread-3485) export TF_CONFIG: {\"cluster\": {\"ps\": [\"172.18.0.10:42459\"], \"chief\": [\"172.18.0.10:46731\"]}, \"task\": {\"type\": \"ps\", \"index\": 0}, \"environment\": \"cloud\"}\n",
      "2025-05-10 20:23:06,920 INFO (MainThread-3485) Starting TensorFlow ps:0 as ps on cluster node 0 on background process\n",
      "Epoch 1/5\n",
      "2025-05-10 20:23:07,725 INFO (MainThread-3484) node: {'executor_id': 0, 'host': '172.18.0.10', 'job_name': 'ps', 'task_index': 0, 'port': 42459, 'tb_pid': 0, 'tb_port': 0, 'addr': ('172.18.0.10', 33969), 'authkey': b'\\x14\\xde\\xfe\\x13\\xd1(Lk\\x82C\\xa9\\x1e\\x07\\xecu\\xb3'}\n",
      "2025-05-10 20:23:07,725 INFO (MainThread-3484) node: {'executor_id': 1, 'host': '172.18.0.10', 'job_name': 'chief', 'task_index': 0, 'port': 46731, 'tb_pid': 0, 'tb_port': 0, 'addr': '/tmp/pymp-9io_fq71/listener-suqag89r', 'authkey': b'\\xff\\xbe\\xb5Y\\x95CE\\x94\\xbb\\x8a\\xda\\x9b\\xa6\\x06\\xd3\\xaf'}\n",
      "2025-05-10 20:23:07,725 INFO (MainThread-3484) export TF_CONFIG: {\"cluster\": {\"ps\": [\"172.18.0.10:42459\"], \"chief\": [\"172.18.0.10:46731\"]}, \"task\": {\"type\": \"chief\", \"index\": 0}, \"environment\": \"cloud\"}\n",
      "2025-05-10 20:23:07,740 INFO (MainThread-3484) Starting TensorFlow chief:0 on cluster node 1 on foreground thread\n",
      " 8/51 [===>..........................] - ETA: 0s - loss: 6.5095 - accuracy: 0.0039Epoch 1/5\n",
      "51/51 [==============================] - 1s 16ms/step - loss: 6.3603 - accuracy: 0.0106 - val_loss: 6.0950 - val_accuracy: 0.0169\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.9480 - accuracy: 0.0144 - val_loss: 5.9928 - val_accuracy: 0.0112\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 5.8412 - accuracy: 0.0181 - val_loss: 6.1165 - val_accuracy: 0.0337\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 2s 21ms/step - loss: 6.3546 - accuracy: 0.0137 - val_loss: 6.1636 - val_accuracy: 0.0056\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 5.7676 - accuracy: 0.0294 - val_loss: 6.0338 - val_accuracy: 0.0112\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 5.9454 - accuracy: 0.0137 - val_loss: 6.0683 - val_accuracy: 0.0056\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 5.7062 - accuracy: 0.0287 - val_loss: 6.0981 - val_accuracy: 0.0337\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.8525 - accuracy: 0.0112 - val_loss: 5.9926 - val_accuracy: 0.0337\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 5.7991 - accuracy: 0.0206 - val_loss: 6.0632 - val_accuracy: 0.0337\n",
      "Epoch 5/5\n",
      " 9/51 [====>.........................] - ETA: 0s - loss: 5.7182 - accuracy: 0.0174    "
     ]
    }
   ],
   "source": [
    "# Modelo para negras\n",
    "entrenar_cnn_distribuida(\n",
    "    data_path=\"/notebooks/datos_cnn/negras/fen_jugadas.parquet\",\n",
    "    model_path=\"/notebooks/datos_cnn/modelo_negras\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19dc2cdc-2314-48da-b445-b2e658d81337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "total 172\n",
      "drwxr-xr-x 2 root root   4096 May 10 19:55 assets\n",
      "-rw-r--r-- 1 root root     55 May 10 20:22 fingerprint.pb\n",
      "-rw-r--r-- 1 root root  16623 May 10 20:22 keras_metadata.pb\n",
      "-rw-r--r-- 1 root root 140745 May 10 20:22 saved_model.pb\n",
      "drwxr-xr-x 2 root root   4096 May 10 20:22 variables\n",
      "IOStream.flush timed out\n",
      "total 172\n",
      "drwxr-xr-x 2 root root   4096 May 10 19:57 assets\n",
      "-rw-r--r-- 1 root root     57 May 10 20:23 fingerprint.pb\n",
      "-rw-r--r-- 1 root root  16623 May 10 20:23 keras_metadata.pb\n",
      "-rw-r--r-- 1 root root 140745 May 10 20:23 saved_model.pb\n",
      "drwxr-xr-x 2 root root   4096 May 10 20:23 variables\n"
     ]
    }
   ],
   "source": [
    "!ls -l /notebooks/datos_cnn/modelo_blancas/\n",
    "!ls -l /notebooks/datos_cnn/modelo_negras/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b17f8-1517-4056-a5f9-9a9f647f26b4",
   "metadata": {},
   "source": [
    "## Evaluación del entrenamiento\n",
    "Hay que hacerlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad0b89-9173-482a-8899-c0542025e154",
   "metadata": {},
   "source": [
    "## Juego contra el Bot estilo Nakamura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba14b947-ce55-4020-bae9-d967d9cd8f66",
   "metadata": {},
   "source": [
    "### 6.1 Nakamura juega con blancas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aaebf73-68b4-4081-a131-6a66451d5dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "Requirement already satisfied: pygame in /usr/local/lib/python3.9/dist-packages (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e43de-23b5-4fba-b1b4-276e083e712d",
   "metadata": {},
   "source": [
    "### Instalar el wrapper de Python para Stockfish pero también se necesita el binario ejecutable en el sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd1e7f-66e3-4b0a-8ff2-a709a44b3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stockfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb0e2d-6326-4115-953a-c4ca8754e92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]"
     ]
    }
   ],
   "source": [
    "# INSTALACION DEL EJECUTABLE\n",
    "#cd /notebooks\n",
    "#rm -rf Stockfish\n",
    "#git clone --branch sf_15 https://github.com/official-stockfish/Stockfish.git\n",
    "#cd Stockfish/src\n",
    "#make build ARCH=x86-64\n",
    "#mkdir -p /notebooks/motor_ejecutable\n",
    "#cp stockfish /notebooks/motor_ejecutable/stockfish\n",
    "#chmod +x /notebooks/motor_ejecutable/stockfish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74006cd5-97b5-4f04-982d-872f90c33d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jugada estilo Nakamura: d7d5 (IA score: 0.1016)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 142\u001b[0m\n\u001b[1;32m    139\u001b[0m board\u001b[38;5;241m.\u001b[39mpush(ai_move)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m running:\n\u001b[0;32m--> 142\u001b[0m     \u001b[43mdraw_board\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mflip()\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m game_over \u001b[38;5;129;01mand\u001b[39;00m board\u001b[38;5;241m.\u001b[39mis_game_over():\n",
      "Cell \u001b[0;32mIn[15], line 126\u001b[0m, in \u001b[0;36mdraw_board\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m    124\u001b[0m img \u001b[38;5;241m=\u001b[39m PIECE_IMAGES\u001b[38;5;241m.\u001b[39mget(piece\u001b[38;5;241m.\u001b[39msymbol())\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img:\n\u001b[0;32m--> 126\u001b[0m     \u001b[43mscreen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSQ_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSQ_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import chess\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from stockfish import Stockfish\n",
    "import os\n",
    "\n",
    "# --- CONFIGURACIÓN ---\n",
    "MODEL_PATH = \"/notebooks/datos_cnn/modelo_blancas\"\n",
    "STOCKFISH_PATH = \"motor_ejecutable/stockfish\"\n",
    "ENCODER_PATH = \"encoder_blancas.npy\"  # Asegúrate de haberlo guardado tras el entrenamiento\n",
    "\n",
    "# Inicializar pygame\n",
    "pygame.init()\n",
    "WIDTH, HEIGHT = 512, 512\n",
    "SQ_SIZE = WIDTH // 8\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Juega contra Nakamura\")\n",
    "\n",
    "# Cargar imágenes con rutas absolutas\n",
    "BASE_DIR = os.getcwd()\n",
    "PIECE_DIR = os.path.join(BASE_DIR, \"pieces\")\n",
    "\n",
    "PIECE_IMAGES = {}\n",
    "PIECE_MAPPING = {\n",
    "    \"r\": \"R1\", \"n\": \"N1\", \"b\": \"B1\", \"q\": \"Q1\", \"k\": \"K1\", \"p\": \"P1\",\n",
    "    \"R\": \"R\", \"N\": \"N\", \"B\": \"B\", \"Q\": \"Q\", \"K\": \"K\", \"P\": \"P\"\n",
    "}\n",
    "for symbol, name in PIECE_MAPPING.items():\n",
    "    PIECE_IMAGES[symbol] = pygame.transform.scale(\n",
    "        pygame.image.load(f\"pieces/{name}.png\"), (SQ_SIZE, SQ_SIZE))\n",
    "\n",
    "# Cargar modelo y encoder\n",
    "model = load_model(MODEL_PATH)\n",
    "encoder_classes = np.load(ENCODER_PATH, allow_pickle=True)\n",
    "\n",
    "# Iniciar motor\n",
    "stockfish = Stockfish(path=STOCKFISH_PATH, parameters={\"Threads\": 2, \"Minimum Thinking Time\": 100})\n",
    "stockfish.set_elo_rating(2800)\n",
    "stockfish.set_skill_level(20)\n",
    "\n",
    "def fen_to_tensor(fen):\n",
    "    piece_to_plane = {\n",
    "        'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "        'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "    }\n",
    "    tensor = np.zeros((8, 8, 12), dtype=np.float32)\n",
    "    fen_board = fen.split(' ')[0]\n",
    "    rows = fen_board.split('/')\n",
    "    for i, row in enumerate(rows):\n",
    "        col = 0\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                col += int(char)\n",
    "            elif char in piece_to_plane:\n",
    "                tensor[i, col, piece_to_plane[char]] = 1\n",
    "                col += 1\n",
    "    return tensor\n",
    "\n",
    "def flip_square_name(uci_move):\n",
    "    col_map = {'a': 'h', 'b': 'g', 'c': 'f', 'd': 'e', 'e': 'd', 'f': 'c', 'g': 'b', 'h': 'a'}\n",
    "    def flip(sq):\n",
    "        col, row = sq[0], sq[1]\n",
    "        return col_map[col] + str(9 - int(row))\n",
    "    return flip(uci_move[:2]) + flip(uci_move[2:4])\n",
    "\n",
    "def predict_move(fen, board, top_n=10, umbral_cp=20):\n",
    "    stockfish.set_fen_position(fen)\n",
    "    eval_info = stockfish.get_evaluation()\n",
    "    \n",
    "    if eval_info[\"type\"] == \"mate\" and eval_info[\"value\"] is not None and eval_info[\"value\"] <= 3:\n",
    "        best_uci = stockfish.get_best_move()\n",
    "        print(\"¡Mate detectado! Stockfish lo ejecuta:\", best_uci)\n",
    "        return chess.Move.from_uci(best_uci)\n",
    "\n",
    "    top_moves_info = stockfish.get_top_moves(top_n)\n",
    "    if not top_moves_info:\n",
    "        print(\"No hay jugadas válidas.\")\n",
    "        return np.random.choice(list(board.legal_moves))\n",
    "\n",
    "    best_eval = top_moves_info[0].get(\"Centipawn\")\n",
    "    if best_eval is None:\n",
    "        print(\"Evaluación no disponible. Stockfish mueve.\")\n",
    "        return chess.Move.from_uci(top_moves_info[0][\"Move\"])\n",
    "\n",
    "    candidatas = [m for m in top_moves_info if abs(best_eval - m.get(\"Centipawn\", 0)) <= umbral_cp]\n",
    "\n",
    "    if len(candidatas) == 1:\n",
    "        best_move = chess.Move.from_uci(candidatas[0][\"Move\"])\n",
    "        print(\"Jugada clara. Stockfish la ejecuta:\", best_move.uci())\n",
    "        return best_move\n",
    "\n",
    "    tensor = fen_to_tensor(fen).reshape(1, 8, 8, 12)\n",
    "    prediction = model.predict(tensor, verbose=0)[0]\n",
    "\n",
    "    scored = []\n",
    "    for move_info in candidatas:\n",
    "        move_uci = move_info[\"Move\"]\n",
    "        try:\n",
    "            idx = np.where(encoder_classes == move_uci)[0][0]\n",
    "            ia_score = prediction[idx]\n",
    "        except IndexError:\n",
    "            ia_score = 0.0\n",
    "        scored.append((move_uci, ia_score))\n",
    "\n",
    "    best_uci, best_score = max(scored, key=lambda x: x[1])\n",
    "    print(f\"\\nJugada estilo Nakamura: {flip_square_name(best_uci)} (IA score: {best_score:.4f})\")\n",
    "    return chess.Move.from_uci(best_uci)\n",
    "\n",
    "def draw_board(board):\n",
    "    colors = [pygame.Color(\"white\"), pygame.Color(\"gray\")]\n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            color = colors[(row + col) % 2]\n",
    "            pygame.draw.rect(screen, color, pygame.Rect(col * SQ_SIZE, row * SQ_SIZE, SQ_SIZE, SQ_SIZE))\n",
    "\n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            visual_row = row\n",
    "            visual_col = col\n",
    "            square = chess.square(7 - visual_col, visual_row)\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                img = PIECE_IMAGES.get(piece.symbol())\n",
    "                if img:\n",
    "                    screen.blit(img, (col * SQ_SIZE, row * SQ_SIZE))\n",
    "\n",
    "# Bucle principal\n",
    "board = chess.Board()\n",
    "running = True\n",
    "selected_square = None\n",
    "game_over = False\n",
    "\n",
    "draw_board(board)\n",
    "pygame.display.flip()\n",
    "\n",
    "# Movimiento de apertura del bot\n",
    "ai_move = predict_move(board.fen(), board)\n",
    "board.push(ai_move)\n",
    "\n",
    "while running:\n",
    "    draw_board(board)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if not game_over and board.is_game_over():\n",
    "        game_over = True\n",
    "        result = board.result()\n",
    "        if board.is_checkmate():\n",
    "            winner = \"Blancas\" if board.turn == chess.BLACK else \"Negras\"\n",
    "            print(f\"Jaque mate. Ganan {winner}\")\n",
    "        else:\n",
    "            print(\"Tablas\")\n",
    "\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "        elif event.type == pygame.MOUSEBUTTONDOWN and not game_over:\n",
    "            x, y = pygame.mouse.get_pos()\n",
    "            col = 7 - (x // SQ_SIZE)\n",
    "            row = y // SQ_SIZE\n",
    "            square = chess.square(col, row)\n",
    "\n",
    "            if selected_square is None:\n",
    "                piece = board.piece_at(square)\n",
    "                if piece and piece.color == chess.BLACK:\n",
    "                    selected_square = square\n",
    "            else:\n",
    "                move = chess.Move(selected_square, square)\n",
    "                if move in board.legal_moves:\n",
    "                    board.push(move)\n",
    "                    if not board.is_game_over():\n",
    "                        ai_move = predict_move(board.fen(), board)\n",
    "                        board.push(ai_move)\n",
    "                selected_square = None\n",
    "\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3599fe-455f-4b79-9ff4-1d502161862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n",
      "['K.png', 'Q1.png', 'K1.png', 'N1.png', 'R.png', 'P.png', 'Q.png', 'N.png', 'R1.png', 'B1.png', 'P1.png', 'B.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())                      # muestra el directorio actual\n",
    "print(os.listdir(\"pieces\"))             # lista archivos en la carpeta pieces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf652058-7ea3-4be6-9b2e-69a1d7f2cedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0557529-0dcd-41d1-934c-37374334b27d",
   "metadata": {},
   "source": [
    "Este tipo de interfaz con pygame debe ejecutarse en un entorno local con GUI, como:\n",
    "\n",
    "Un Jupyter Notebook instalado directamente en tu PC (no dentro de contenedor Docker sin GUI)\n",
    "\n",
    "Un script .py ejecutado desde tu sistema operativo con Python local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f6d28cb-f317-4937-be66-481b029e3d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]"
     ]
    }
   ],
   "source": [
    "with open(\"nakamura_bot_blancas.py\", \"w\") as f:\n",
    "    f.write(\"\"\"import pygame\n",
    "import chess\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from stockfish import Stockfish\n",
    "import os\n",
    "\n",
    "# Configuración Pygame\n",
    "pygame.init()\n",
    "WIDTH, HEIGHT = 512, 512\n",
    "SQ_SIZE = WIDTH // 8\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Juega contra Nakamura\")\n",
    "\n",
    "# Cargar imágenes de piezas\n",
    "PIECE_IMAGES = {}\n",
    "PIECE_MAPPING = {\n",
    "    \"r\": \"R1\", \"n\": \"N1\", \"b\": \"B1\", \"q\": \"Q1\", \"k\": \"K1\", \"p\": \"P1\",\n",
    "    \"R\": \"R\", \"N\": \"N\", \"B\": \"B\", \"Q\": \"Q\", \"K\": \"K\", \"P\": \"P\"\n",
    "}\n",
    "for symbol, name in PIECE_MAPPING.items():\n",
    "    PIECE_IMAGES[symbol] = pygame.transform.scale(\n",
    "        pygame.image.load(f\"pieces/{name}.png\"), (SQ_SIZE, SQ_SIZE))\n",
    "\n",
    "# Cargar modelo y encoder\n",
    "MODEL_PATH = \"datos_cnn/modelo_blancas\"\n",
    "ENCODER_PATH = \"encoder_blancas.npy\"\n",
    "STOCKFISH_PATH = \"motor_ejecutable/stockfish\"\n",
    "\n",
    "model = load_model(MODEL_PATH, compile=False)\n",
    "encoder_classes = np.load(ENCODER_PATH, allow_pickle=True)\n",
    "\n",
    "# Iniciar Stockfish\n",
    "stockfish = Stockfish(path=STOCKFISH_PATH, parameters={\n",
    "    \"Threads\": 2,\n",
    "    \"Minimum Thinking Time\": 100\n",
    "})\n",
    "stockfish.set_elo_rating(2800)\n",
    "stockfish.set_skill_level(20)\n",
    "\n",
    "# FEN a tensor\n",
    "def fen_to_tensor(fen):\n",
    "    piece_to_plane = {\n",
    "        'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "        'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "    }\n",
    "    tensor = np.zeros((8, 8, 12), dtype=np.float32)\n",
    "    fen_board = fen.split(' ')[0]\n",
    "    rows = fen_board.split('/')\n",
    "    for i, row in enumerate(rows):\n",
    "        col = 0\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                col += int(char)\n",
    "            elif char in piece_to_plane:\n",
    "                tensor[i, col, piece_to_plane[char]] = 1\n",
    "                col += 1\n",
    "    return tensor\n",
    "\n",
    "# Inversión visual\n",
    "def flip_square_name(uci_move):\n",
    "    col_map = {'a': 'h', 'b': 'g', 'c': 'f', 'd': 'e', 'e': 'd', 'f': 'c', 'g': 'b', 'h': 'a'}\n",
    "    def flip(sq):\n",
    "        col, row = sq[0], sq[1]\n",
    "        return col_map[col] + str(9 - int(row))\n",
    "    return flip(uci_move[:2]) + flip(uci_move[2:4])\n",
    "\n",
    "# Jugada IA\n",
    "def predict_move(fen, board, top_n=10, umbral_cp=20):\n",
    "    stockfish.set_fen_position(fen)\n",
    "    eval_info = stockfish.get_evaluation()\n",
    "\n",
    "    if eval_info[\"type\"] == \"mate\" and eval_info[\"value\"] is not None and eval_info[\"value\"] <= 3:\n",
    "        best_uci = stockfish.get_best_move()\n",
    "        print(\"¡Mate detectado! Stockfish lo ejecuta:\", best_uci)\n",
    "        return chess.Move.from_uci(best_uci)\n",
    "\n",
    "    top_moves_info = stockfish.get_top_moves(top_n)\n",
    "    if not top_moves_info:\n",
    "        print(\"No hay jugadas válidas.\")\n",
    "        return np.random.choice(list(board.legal_moves))\n",
    "\n",
    "    best_eval = top_moves_info[0].get(\"Centipawn\")\n",
    "    if best_eval is None:\n",
    "        print(\"Evaluación no disponible. Stockfish mueve.\")\n",
    "        return chess.Move.from_uci(top_moves_info[0][\"Move\"])\n",
    "\n",
    "    candidatas = []\n",
    "    for move_info in top_moves_info:\n",
    "        cp = move_info.get(\"Centipawn\")\n",
    "        if cp is not None and abs(best_eval - cp) <= umbral_cp:\n",
    "            candidatas.append(move_info)\n",
    "\n",
    "    if len(candidatas) == 1:\n",
    "        best_move = chess.Move.from_uci(candidatas[0][\"Move\"])\n",
    "        print(\"Jugada clara. Stockfish la ejecuta:\", best_move.uci())\n",
    "        return best_move\n",
    "\n",
    "    tensor = fen_to_tensor(fen).reshape(1, 8, 8, 12)\n",
    "    prediction = model.predict(tensor, verbose=0)[0]\n",
    "\n",
    "    scored = []\n",
    "    for move_info in candidatas:\n",
    "        move_uci = move_info[\"Move\"]\n",
    "        try:\n",
    "            idx = np.where(encoder_classes == move_uci)[0][0]\n",
    "            ia_score = prediction[idx]\n",
    "        except IndexError:\n",
    "            ia_score = 0.0\n",
    "        scored.append((move_uci, ia_score))\n",
    "\n",
    "    best_uci, best_score = max(scored, key=lambda x: x[1])\n",
    "    print(f\"\\\\nJugada estilo Nakamura: {flip_square_name(best_uci)} (IA score: {best_score:.4f})\")\n",
    "    return chess.Move.from_uci(best_uci)\n",
    "\n",
    "# Dibujar tablero\n",
    "def draw_board(board):\n",
    "    colors = [pygame.Color(\"white\"), pygame.Color(\"gray\")]\n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            color = colors[(row + col) % 2]\n",
    "            pygame.draw.rect(screen, color, pygame.Rect(col * SQ_SIZE, row * SQ_SIZE, SQ_SIZE, SQ_SIZE))\n",
    "\n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            visual_row = row\n",
    "            visual_col = col\n",
    "            square = chess.square(7 - visual_col, visual_row)\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                img = PIECE_IMAGES.get(piece.symbol())\n",
    "                if img:\n",
    "                    screen.blit(img, (col * SQ_SIZE, row * SQ_SIZE))\n",
    "\n",
    "# Juego principal\n",
    "board = chess.Board()\n",
    "running = True\n",
    "selected_square = None\n",
    "game_over = False\n",
    "\n",
    "draw_board(board)\n",
    "pygame.display.flip()\n",
    "\n",
    "# Primer movimiento del bot (blancas)\n",
    "ai_move = predict_move(board.fen(), board)\n",
    "board.push(ai_move)\n",
    "\n",
    "while running:\n",
    "    draw_board(board)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if not game_over and board.is_game_over():\n",
    "        game_over = True\n",
    "        result = board.result()\n",
    "        if board.is_checkmate():\n",
    "            winner = \"Blancas\" if board.turn == chess.BLACK else \"Negras\"\n",
    "            print(f\"Jaque mate. Ganan {winner}\")\n",
    "        else:\n",
    "            print(\"Tablas\")\n",
    "\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "        elif event.type == pygame.MOUSEBUTTONDOWN and not game_over:\n",
    "            x, y = pygame.mouse.get_pos()\n",
    "            col = 7 - (x // SQ_SIZE)\n",
    "            row = y // SQ_SIZE\n",
    "            square = chess.square(col, row)\n",
    "\n",
    "            if selected_square is None:\n",
    "                piece = board.piece_at(square)\n",
    "                if piece and piece.color == chess.BLACK:\n",
    "                    selected_square = square\n",
    "            else:\n",
    "                move = chess.Move(selected_square, square)\n",
    "                if move in board.legal_moves:\n",
    "                    board.push(move)\n",
    "                    if not board.is_game_over():\n",
    "                        ai_move = predict_move(board.fen(), board)\n",
    "                        board.push(ai_move)\n",
    "                selected_square = None\n",
    "\n",
    "pygame.quit()\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed2b4c-f7d2-4b90-8a0b-d931c25b3e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42897d-6e4e-4a37-9c03-c772341942c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instalar comunicación X11\n",
    "\n",
    "apt update && apt install -y x11-utils x11-xserver-utils\n",
    "\n",
    "apt update && apt install -y x11-utils x11-apps\n",
    "\n",
    "Local (fuera del contenedor): xhost +local:root\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff35d93b-94e3-421a-94d8-d6993bba5a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b1107d5-2cdf-42f5-a6d3-ef38f72e0913",
   "metadata": {},
   "source": [
    "En el docker-compose, en spark-client: \n",
    "services:\n",
    "  spark-client:\n",
    "    # ... tus otras configuraciones\n",
    "    environment:\n",
    "      - DISPLAY=${DISPLAY}\n",
    "    volumes:\n",
    "      - /tmp/.X11-unix:/tmp/.X11-unix\n",
    "\n",
    "En el host (fuera de docker): xhost +local:root\n",
    "\n",
    "docker compose down\n",
    "docker compose up -d\n",
    "\n",
    "Dentro de spark-client: \n",
    "\n",
    "\n",
    "echo $DISPLAY\n",
    "Debería decir algo como :0\n",
    "\n",
    "apt update && apt install -y x11-apps\n",
    "\n",
    "xclock\n",
    "Debería aparecer una ventana de reloj\n",
    "\n",
    "cd notebooks\n",
    "\n",
    "python3 nakamura_bot_blancas.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8b602-69fe-4548-9673-ea36e7a04b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29911378-64db-4c14-8e71-bfd11fae79a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17b1f8e7-6f88-4cd2-8fab-5c4ecff7b918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 11:37:23.932746: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.0071 - loss: 6.8118 - val_accuracy: 0.0031 - val_loss: 6.4299\n",
      "Epoch 2/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: 6.3681 - val_accuracy: 0.0125 - val_loss: 6.4215\n",
      "Epoch 3/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0171 - loss: 6.2490 - val_accuracy: 0.0094 - val_loss: 6.4129\n",
      "Epoch 4/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0202 - loss: 6.0973 - val_accuracy: 0.0250 - val_loss: 6.4572\n",
      "Epoch 5/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0246 - loss: 5.9505 - val_accuracy: 0.0219 - val_loss: 6.5551\n",
      "Epoch 6/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0329 - loss: 5.8137 - val_accuracy: 0.0312 - val_loss: 6.5765\n",
      "Epoch 7/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0437 - loss: 5.6680 - val_accuracy: 0.0344 - val_loss: 6.6006\n",
      "Epoch 8/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0515 - loss: 5.3731 - val_accuracy: 0.0312 - val_loss: 7.0053\n",
      "Epoch 9/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0537 - loss: 5.1736 - val_accuracy: 0.0406 - val_loss: 7.0219\n",
      "Epoch 10/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0538 - loss: 4.9638 - val_accuracy: 0.0500 - val_loss: 7.4603\n"
     ]
    }
   ],
   "source": [
    "## ENTRENAMIENTO LOCAL EN SPARK-CLIENT (USÉ EL ANTERIOR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Cargar datos exportados desde Spark\n",
    "df = pd.read_parquet(\"/shared/fen_jugadas.parquet\")\n",
    "\n",
    "# Convertir a tensores NumPy\n",
    "X = np.array(df[\"features\"].tolist()).reshape(-1, 8, 8, 12)\n",
    "y = df[\"label\"].values.astype(int)\n",
    "\n",
    "# Dividir en entrenamiento y validación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Definir el modelo CNN\n",
    "model = Sequential([\n",
    "    Input(shape=(8, 8, 12)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar y entrenar\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Guardar modelo\n",
    "model.save(\"/shared/modelo_nakamura.keras\")\n",
    "np.save(\"/shared/encoder.npy\", np.unique(y))  # Etiquetas numéricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b310df1-f86a-41e6-a71f-5634ae917f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4447e-4d8f-44c1-84f9-96ba2de9e49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3dc69e-2f71-4c9d-85b8-09defbb62665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ebfc8-8271-4c67-aada-416333531f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095fc02-be1d-40de-9af5-52a6c5e17fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d36558-3eee-4175-9acf-bddc83c39835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abb744c1-09df-46fe-9f10-59eebca7cc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features', 'label']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, IntegerType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Codificar FEN como vector plano 768 (8x8x12)\n",
    "def fen_to_flat_vector(fen):  \n",
    "    piece_to_plane = {\n",
    "        'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "        'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "    }\n",
    "    \n",
    "    tensor = np.zeros((8, 8, 12), dtype=np.float32)\n",
    "    fen_board = fen.split(' ')[0]\n",
    "    rows = fen_board.split('/')\n",
    "    \n",
    "    for i, row in enumerate(rows):\n",
    "        col = 0\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                col += int(char)\n",
    "            elif char in piece_to_plane:\n",
    "                plane = piece_to_plane[char]\n",
    "                tensor[i, col, plane] = 1\n",
    "                col += 1\n",
    "    return tensor.flatten().tolist()\n",
    "\n",
    "# UDF para usar en Spark\n",
    "fen_udf = udf(fen_to_flat_vector, ArrayType(FloatType()))\n",
    "\n",
    "# Aplicar UDF para obtener features\n",
    "df_ml = df_jugadas.withColumn(\"features\", fen_udf(col(\"FEN\")))\n",
    "\n",
    "# Codificar movimiento como etiqueta\n",
    "indexer = StringIndexer(inputCol=\"Move\", outputCol=\"label\")\n",
    "indexer_model = indexer.fit(df_ml)\n",
    "df_ml = indexer_model.transform(df_ml)\n",
    "\n",
    "# Seleccionar columnas relevantes para MLlib\n",
    "df_final = df_ml.select(\"features\", \"label\")\n",
    "\n",
    "# Mostrar ejemplo\n",
    "# df_final.show(3, truncate=False)\n",
    "\n",
    "print(df_final.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f1e94c-447f-41c0-bc80-86018d7a615e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc2b3fd-922c-4ea4-bddb-7c81256f1553",
   "metadata": {},
   "source": [
    "## An치lisis de partidas de ajedrez con Stockfish\n",
    "\n",
    "En este proyecto se han probado distintas estrategias para analizar partidas de ajedrez en paralelo usando Apache Spark. Sin embargo, algunas de ellas no ofrecieron mejoras en rendimiento cuando se ejecutaron en un entorno local compuesto por contenedores Docker. A continuaci칩n se explica por qu칠.\n",
    "\n",
    "\n",
    "###  Estrategia 1: An치lisis con Spark por partida (flatMap + mapPartitions)\n",
    "\n",
    "- Cada partida individual se trat칩 como una unidad de trabajo en Spark.\n",
    "- El motor `Stockfish` se ejecutaba dentro de cada partici칩n.\n",
    "- El resultado se recolectaba en el driver como un 칰nico DataFrame.\n",
    "\n",
    "#### Problemas en entorno local (Docker):\n",
    "- Los contenedores Docker comparten CPU y disco del host, no son nodos f칤sicos reales.\n",
    "- Cada partici칩n lanza su propia instancia de `Stockfish`, saturando los recursos del sistema.\n",
    "- No se aprovechan m칰ltiples nodos f칤sicos ni almacenamiento distribuido.\n",
    "- Resultado: rendimiento peor que el an치lisis secuencial local.\n",
    "\n",
    "####  칔til en entornos reales si:\n",
    "- Se dispone de un cl칰ster Spark distribuido con nodos f칤sicos separados.\n",
    "- `Stockfish` est치 disponible en todos los nodos.\n",
    "- Se procesan decenas de miles de partidas.\n",
    "\n",
    "---\n",
    "\n",
    "### Estrategia 2: Un nodo procesa cada archivo con Spark (map por archivo)\n",
    "\n",
    "- Cada archivo `.pgn` completo se procesaba por un nodo.\n",
    "- El an치lisis se hac칤a con `Stockfish` y se guardaban los resultados en `.parquet`.\n",
    "\n",
    "####  Problemas en entorno local (Docker):\n",
    "- Los contenedores comparten recursos del host, lo que limita la paralelizaci칩n efectiva.\n",
    "- Varias instancias de `Stockfish` compitiendo generan cuellos de botella.\n",
    "- Los `print()` y barras de progreso (`tqdm`) no se muestran en la notebook, ya que Spark no reenv칤a la salida est치ndar desde los ejecutores al driver.\n",
    "\n",
    "#### 칔til en entornos reales cuando:\n",
    "- Existen nodos f칤sicos con CPUs independientes.\n",
    "- Hay muchos archivos `.pgn` bien distribuidos.\n",
    "\n",
    "---\n",
    "\n",
    " Por tanto, aunque Spark es potente para procesamiento distribuido, no ofrece beneficios reales en un entorno local con contenedores Docker.  Para trabajos medianos o pruebas desde notebooks, el an치lisis secuencial (uno a uno) es **m치s r치pido, controlable y f치cil de depurar**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec94cc2-cce2-4096-b554-a9a76267f152",
   "metadata": {},
   "source": [
    "## C칩digo efectivo a realizar en un cluster real (estrategia 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce547eb4-0a52-4b38-9303-16490970ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/18 17:32:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/18 17:32:26 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pathlib import Path\n",
    "\n",
    "# Crear sesi칩n de Spark distribuida (usar치 nodos del cl칰ster)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Analisis_PGN_Distribuido_HDFS\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Ruta de entrada con archivos .pgn en HDFS (cada uno con ~50 partidas)\n",
    "ruta_entrada_hdfs = \"hdfs:///user/ajedrez/raw/seleccionados/\"\n",
    "\n",
    "# Ruta donde se guardar치n los resultados individuales en HDFS\n",
    "ruta_salida_hdfs = \"hdfs:///user/ajedrez/analizados_grupo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02071c8-e040-424e-881f-5f078ddb69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_pgn(pgn_path: str, stockfish_path: str = \"stockfish.exe\"):\n",
    "    log_path = \"errores_pgn.log\"\n",
    "    central_squares = {\"d4\", \"e4\", \"d5\", \"e5\"}\n",
    "    \n",
    "    piece_value = {\"p\": 1, \"n\": 3, \"b\": 3, \"r\": 5, \"q\": 9, \"k\": 0}\n",
    "    stockfish = Stockfish(path=stockfish_path)\n",
    "\n",
    "    players = defaultdict(lambda: {\n",
    "        \"fide_id\": None,\n",
    "        \"elo\": [],\n",
    "        \"resultados\": [],\n",
    "        \"partidas\": 0,\n",
    "        \"movimientos_total\": [],\n",
    "        \"enroque\": [],\n",
    "        \"intercambio_piezas\": [],\n",
    "        \"sacrificios\": [],\n",
    "        \"mov_peones\": [],\n",
    "        \"mov_centrales\": [],\n",
    "        \"cod_eco\": [],\n",
    "        \"evaluacion_cp\": [],\n",
    "        \"evaluacion_cp_apertura\": [],\n",
    "        \"evaluacion_cp_mediojuego\": [],\n",
    "        \"evaluacion_cp_final\": [],\n",
    "        \"errores_graves\": [],\n",
    "        \"errores\": [],\n",
    "        \"errores_leves\": [],\n",
    "        \"errores_graves_apertura\": [],\n",
    "        \"errores_graves_mediojuego\": [],\n",
    "        \"errores_graves_final\": [],\n",
    "        \"errores_apertura\": [],\n",
    "        \"errores_mediojuego\": [],\n",
    "        \"errores_final\": [],\n",
    "        \"errores_leves_apertura\": [],\n",
    "        \"errores_leves_mediojuego\": [],\n",
    "        \"errores_leves_final\": [],\n",
    "        \"evento\": [],\n",
    "        \"lugar\": [],\n",
    "        \"pgn\": [],\n",
    "        \"san\": [],\n",
    "        \"fechas\": []\n",
    "    })\n",
    "\n",
    "    jugadores_objetivo = set()\n",
    "    with open(pgn_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "            jugadores_objetivo.add(game.headers.get(\"White\", \"Unknown\"))\n",
    "            jugadores_objetivo.add(game.headers.get(\"Black\", \"Unknown\"))\n",
    "    jugadores_objetivo = {j for j in jugadores_objetivo if j not in {\"?\", \"Unknown\", \"\"}}\n",
    "\n",
    "    with open(pgn_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        total_games = sum(1 for _ in iter(lambda: chess.pgn.read_game(f), None))\n",
    "\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(f\"Registro de errores - {datetime.datetime.now()}\\n\\n\")\n",
    "\n",
    "    with open(pgn_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for i in tqdm(range(total_games), desc=\"Analizando partidas\"):\n",
    "            try:\n",
    "                game = chess.pgn.read_game(f)\n",
    "                if game is None:\n",
    "                    break\n",
    "\n",
    "                white = game.headers.get(\"White\", \"Unknown\")\n",
    "                black = game.headers.get(\"Black\", \"Unknown\")\n",
    "                white_fide = game.headers.get(\"WhiteFideId\", \"None\")\n",
    "                black_fide = game.headers.get(\"BlackFideId\", \"None\")\n",
    "                white_elo = int(game.headers.get(\"WhiteElo\", \"0\"))\n",
    "                black_elo = int(game.headers.get(\"BlackElo\", \"0\"))\n",
    "                resultado_raw = game.headers.get(\"Result\", \"*\")\n",
    "\n",
    "                exporter = chess.pgn.StringExporter(headers=True, variations=False, comments=False)\n",
    "                pgn_str = game.accept(exporter)\n",
    "\n",
    "                board = game.board()\n",
    "                jugadas_san = []\n",
    "                for move in game.mainline_moves():\n",
    "                    jugadas_san.append(board.san(move))\n",
    "                    board.push(move)\n",
    "\n",
    "                resultado_white, resultado_black = {\n",
    "                    \"1-0\": (1.0, 0.0),\n",
    "                    \"0-1\": (0.0, 1.0),\n",
    "                    \"1/2-1/2\": (0.5, 0.5)\n",
    "                }.get(resultado_raw, (None, None))\n",
    "\n",
    "                if white not in jugadores_objetivo and black not in jugadores_objetivo:\n",
    "                    continue\n",
    "\n",
    "                eco = game.headers.get(\"ECO\", \"None\")\n",
    "                fecha_str = game.headers.get(\"Date\", None)\n",
    "                try:\n",
    "                    fecha = datetime.datetime.strptime(fecha_str, \"%Y.%m.%d\").date()\n",
    "                except:\n",
    "                    fecha = None\n",
    "\n",
    "                game_counted = {\"W\": False, \"B\": False}\n",
    "                board = game.board()\n",
    "                move_number = 0\n",
    "                moves_list = []\n",
    "                jugador_stats_temporales = {\"W\": defaultdict(int), \"B\": defaultdict(int)}\n",
    "                contador_jugadas_por_jugador = {\"W\": 0, \"B\": 0}\n",
    "                evaluaciones_por_fase = {\"apertura\": [], \"mediojuego\": [], \"final\": [], \"total\": []}\n",
    "\n",
    "                for move in game.mainline_moves():\n",
    "                    move_number += 1\n",
    "                    current_player = white if board.turn else black\n",
    "                    color_tag = \"W\" if board.turn else \"B\"\n",
    "\n",
    "                    if current_player not in jugadores_objetivo:\n",
    "                        board.push(move)\n",
    "                        continue\n",
    "\n",
    "                    contador_jugadas_por_jugador[color_tag] += 1\n",
    "\n",
    "                    key = (current_player, color_tag)\n",
    "                    stats = players[key]\n",
    "                    stats_temp = jugador_stats_temporales[color_tag]\n",
    "\n",
    "                    if not game_counted[color_tag]:\n",
    "                        stats[\"partidas\"] += 1\n",
    "                        stats[\"cod_eco\"].append(eco)\n",
    "                        stats[\"fide_id\"] = white_fide if color_tag == \"W\" else black_fide\n",
    "                        stats[\"elo\"].append(white_elo if color_tag == \"W\" else black_elo)\n",
    "                        stats[\"resultados\"].append(resultado_white if color_tag == \"W\" else resultado_black)\n",
    "                        if fecha:\n",
    "                            stats[\"fechas\"].append(fecha)\n",
    "                        stats[\"evento\"].append(game.headers.get(\"Event\", \"\"))\n",
    "                        stats[\"lugar\"].append(game.headers.get(\"Site\", \"\"))\n",
    "                        stats[\"pgn\"].append(pgn_str)\n",
    "                        stats[\"san\"].append(jugadas_san)\n",
    "\n",
    "                    game_counted[color_tag] = True\n",
    "                    uci = move.uci()\n",
    "                    moves_list.append(uci)\n",
    "\n",
    "                    try:\n",
    "                        stockfish.set_position(moves_list[:-1])\n",
    "                        eval_before = stockfish.get_evaluation()[\"value\"] or 0\n",
    "                        stockfish.set_position(moves_list)\n",
    "                        eval_after = stockfish.get_evaluation()[\"value\"] or 0\n",
    "                    except Exception as sf_error:\n",
    "                        raise RuntimeError(f\"Stockfish error en jugada {uci}: {sf_error}\")\n",
    "\n",
    "                    loss = abs(eval_before - eval_after)\n",
    "                    fase = \"apertura\" if move_number <= 20 else \"mediojuego\" if move_number <= 60 else \"final\"\n",
    "                    eval_abs = abs(eval_after)\n",
    "                    evaluaciones_por_fase[fase].append(eval_abs)\n",
    "                    evaluaciones_por_fase[\"total\"].append(eval_abs)\n",
    "\n",
    "                    piece = board.piece_at(move.from_square)\n",
    "                    if not board.is_legal(move):\n",
    "                        raise ValueError(f\"Movimiento ilegal: {uci} en {board.fen()}\")\n",
    "\n",
    "                    san = board.san(move)\n",
    "                    board.push(move)\n",
    "\n",
    "                    stats_temp[\"movimientos_total\"] += 1\n",
    "\n",
    "                    if san in [\"O-O\", \"O-O-O\"] and \"enroque\" not in stats_temp:\n",
    "                        stats_temp[\"enroque\"] = contador_jugadas_por_jugador[color_tag]\n",
    "\n",
    "                    if \"x\" in san:\n",
    "                        stats_temp[\"intercambio_piezas\"] += 1\n",
    "                        capturada = board.piece_at(move.to_square)\n",
    "                        if capturada:\n",
    "                            atacante = piece_value[piece.symbol().lower()]\n",
    "                            capturada_valor = piece_value[capturada.symbol().lower()]\n",
    "                            if atacante > capturada_valor and loss < 150:\n",
    "                                stats_temp[\"sacrificios\"] += 1\n",
    "\n",
    "                    if piece and piece.symbol().lower() == \"p\":\n",
    "                        stats_temp[\"mov_peones\"] += 1\n",
    "\n",
    "                    if chess.square_name(move.to_square) in central_squares:\n",
    "                        stats_temp[\"mov_centrales\"] += 1\n",
    "\n",
    "                    if loss > 300:\n",
    "                        stats_temp[\"errores_graves\"] += 1\n",
    "                        stats_temp[f\"blunders_{fase}\"] += 1\n",
    "                    elif loss > 100:\n",
    "                        stats_temp[\"errores\"] += 1\n",
    "                        stats_temp[f\"errores_{fase}\"] += 1\n",
    "                    elif loss > 50:\n",
    "                        stats_temp[\"errores_leves\"] += 1\n",
    "                        stats_temp[f\"imprecisiones_{fase}\"] += 1\n",
    "\n",
    "                for color_tag, jugador in [(\"W\", white), (\"B\", black)]:\n",
    "                    if jugador in jugadores_objetivo:\n",
    "                        stats = players[(jugador, color_tag)]\n",
    "                        temp = jugador_stats_temporales[color_tag]\n",
    "                        stats[\"movimientos_total\"].append(temp[\"movimientos_total\"])\n",
    "                        stats[\"mov_peones\"].append(temp[\"mov_peones\"])\n",
    "                        stats[\"mov_centrales\"].append(temp[\"mov_centrales\"])\n",
    "                        stats[\"intercambio_piezas\"].append(temp[\"intercambio_piezas\"])\n",
    "                        stats[\"sacrificios\"].append(temp[\"sacrificios\"])\n",
    "                        stats[\"enroque\"].append(temp[\"enroque\"] if \"enroque\" in temp else 0)\n",
    "\n",
    "                        for fase_eval in [\"total\", \"apertura\", \"mediojuego\", \"final\"]:\n",
    "                            lista = evaluaciones_por_fase[fase_eval]\n",
    "                            campo = f\"evaluacion_cp\" if fase_eval == \"total\" else f\"evaluacion_cp_{fase_eval}\"\n",
    "                            stats[campo].append(statistics.mean(lista) if lista else None)\n",
    "\n",
    "                        errores_map = {\n",
    "                            \"errores_graves\": \"errores_graves\",\n",
    "                            \"errores\": \"errores\",\n",
    "                            \"errores_leves\": \"errores_leves\",\n",
    "                            \"errores_graves_apertura\": \"blunders_apertura\",\n",
    "                            \"errores_graves_mediojuego\": \"blunders_mediojuego\",\n",
    "                            \"errores_graves_final\": \"blunders_final\",\n",
    "                            \"errores_apertura\": \"errores_apertura\",\n",
    "                            \"errores_mediojuego\": \"errores_mediojuego\",\n",
    "                            \"errores_final\": \"errores_final\",\n",
    "                            \"errores_leves_apertura\": \"imprecisiones_apertura\",\n",
    "                            \"errores_leves_mediojuego\": \"imprecisiones_mediojuego\",\n",
    "                            \"errores_leves_final\": \"imprecisiones_final\"\n",
    "                        }\n",
    "\n",
    "                        for campo_destino, campo_temp in errores_map.items():\n",
    "                            valor = temp.get(campo_temp, 0)\n",
    "                            stats[campo_destino].append(valor)\n",
    "\n",
    "            except Exception as e:\n",
    "                msg = f\" Error en partida #{i+1} ({white} vs {black}): {e}\"\n",
    "                print(\"\\n\" + msg)\n",
    "                with open(log_path, \"a\", encoding=\"utf-8\") as log_file:\n",
    "                    log_file.write(msg + \"\\n\")\n",
    "\n",
    "    filas = []\n",
    "    for (nombre, color), datos in players.items():\n",
    "        for i in range(datos[\"partidas\"]):\n",
    "            fila = {\"jugador\": nombre, \"color\": color, \"fide_id\": datos.get(\"fide_id\", \"\")}\n",
    "            for campo, valores in datos.items():\n",
    "                if isinstance(valores, list) and len(valores) > i:\n",
    "                    fila[campo] = valores[i]\n",
    "            filas.append(fila)\n",
    "\n",
    "    df_partidas = pd.DataFrame(filas)\n",
    "    df_partidas[\"fechas\"] = pd.to_datetime(df_partidas[\"fechas\"], errors=\"coerce\")\n",
    "    df_partidas = df_partidas.fillna(np.nan)\n",
    "\n",
    "    nombre_archivo = f\"analisis_{os.path.splitext(os.path.basename(pgn_path))[0]}.parquet\"\n",
    "    df_partidas.to_parquet(nombre_archivo, engine=\"pyarrow\", coerce_timestamps=\"ms\")\n",
    "    return nombre_archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfdc249f-d0f2-4933-aeac-2b3914792613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import datetime\n",
    "import statistics\n",
    "import chess.pgn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from stockfish import Stockfish\n",
    "\n",
    "def procesar_y_guardar_en_hdfs(archivo):\n",
    "    from pathlib import Path\n",
    "    \n",
    "    nombre_archivo = Path(archivo[0]).stem\n",
    "    contenido_pgn = archivo[1]\n",
    "    \n",
    "    # Guardar temporalmente en disco local\n",
    "    ruta_temp = f\"/tmp/{nombre_archivo}.pgn\"\n",
    "    with open(ruta_temp, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(contenido_pgn)\n",
    "\n",
    "    try:\n",
    "        salida = analizar_pgn(\n",
    "            pgn_path=ruta_temp,\n",
    "            stockfish_path=\"stockfish\",\n",
    "            log_errores=False,\n",
    "            mostrar_progreso=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        parquet_local = Path(salida)\n",
    "        parquet_hdfs = f\"{ruta_salida_hdfs}analisis_{nombre_archivo}.parquet\"\n",
    "        \n",
    "        # Subir al HDFS (sobrescribe si existe)\n",
    "        os.system(f\"hdfs dfs -put -f {parquet_local} {parquet_hdfs}\")\n",
    "        print(f\"Subido a HDFS: {parquet_hdfs}\")\n",
    "        return parquet_hdfs\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error en archivo {nombre_archivo}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40a6993-62fd-497b-bb99-0914edc66cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "游닍 Archivos .parquet generados en HDFS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Leer archivos desde HDFS como RDD [(ruta, contenido), ...]\n",
    "rdd_archivos = spark.sparkContext.wholeTextFiles(ruta_entrada_hdfs)\n",
    "\n",
    "# Analizar y guardar resultados por archivo en paralelo en el cl칰ster\n",
    "resultados = rdd_archivos.map(procesar_y_guardar_en_hdfs).collect()\n",
    "\n",
    "# Mostrar los archivos subidos\n",
    "print(\"\\n Archivos .parquet generados en HDFS:\")\n",
    "for archivo in resultados:\n",
    "    if archivo:\n",
    "        print(\"   -\", archivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19064dfe-e326-494f-8deb-68305e9c7737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc2b3fd-922c-4ea4-bddb-7c81256f1553",
   "metadata": {},
   "source": [
    "## Análisis de partidas de ajedrez con Stockfish\n",
    "\n",
    "En este proyecto se han probado distintas estrategias para analizar partidas de ajedrez en paralelo usando Apache Spark. Sin embargo, algunas de ellas no ofrecieron mejoras en rendimiento cuando se ejecutaron en un entorno local compuesto por contenedores Docker. A continuación se explica por qué.\n",
    "\n",
    "\n",
    "###  Estrategia 1: Análisis con Spark por partida (flatMap + mapPartitions)\n",
    "\n",
    "- Cada partida individual se trató como una unidad de trabajo en Spark.\n",
    "- El motor `Stockfish` se ejecutaba dentro de cada partición.\n",
    "- El resultado se recolectaba en el driver como un único DataFrame.\n",
    "\n",
    "#### Problemas en entorno local (Docker):\n",
    "- Los contenedores Docker comparten CPU y disco del host, no son nodos físicos reales.\n",
    "- Cada partición lanza su propia instancia de `Stockfish`, saturando los recursos del sistema.\n",
    "- No se aprovechan múltiples nodos físicos ni almacenamiento distribuido.\n",
    "- Resultado: rendimiento peor que el análisis secuencial local.\n",
    "\n",
    "####  Útil en entornos reales si:\n",
    "- Se dispone de un clúster Spark distribuido con nodos físicos separados.\n",
    "- `Stockfish` está disponible en todos los nodos.\n",
    "- Se procesan decenas de miles de partidas.\n",
    "\n",
    "---\n",
    "\n",
    "### Estrategia 2: Un nodo procesa cada archivo con Spark (map por archivo)\n",
    "\n",
    "- Cada archivo `.pgn` completo se procesaba por un nodo.\n",
    "- El análisis se hacía con `Stockfish` y se guardaban los resultados en `.parquet`.\n",
    "\n",
    "####  Problemas en entorno local (Docker):\n",
    "- Los contenedores comparten recursos del host, lo que limita la paralelización efectiva.\n",
    "- Varias instancias de `Stockfish` compitiendo generan cuellos de botella.\n",
    "- Los `print()` y barras de progreso (`tqdm`) no se muestran en la notebook, ya que Spark no reenvía la salida estándar desde los ejecutores al driver.\n",
    "\n",
    "#### Útil en entornos reales cuando:\n",
    "- Existen nodos físicos con CPUs independientes.\n",
    "- Hay muchos archivos `.pgn` bien distribuidos.\n",
    "\n",
    "---\n",
    "\n",
    " Por tanto, aunque Spark es potente para procesamiento distribuido, no ofrece beneficios reales en un entorno local con contenedores Docker.  Para trabajos medianos o pruebas desde notebooks, el análisis secuencial (uno a uno) es **más rápido, controlable y fácil de depurar**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec94cc2-cce2-4096-b554-a9a76267f152",
   "metadata": {},
   "source": [
    "## Código efectivo a realizar en un cluster real (estrategia 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce547eb4-0a52-4b38-9303-16490970ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/18 17:32:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/18 17:32:26 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pathlib import Path\n",
    "\n",
    "# Crear sesión de Spark distribuida (usará nodos del clúster)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Analisis_PGN_Distribuido_HDFS\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Ruta de entrada con archivos .pgn en HDFS (cada uno con ~50 partidas)\n",
    "ruta_entrada_hdfs = \"hdfs:///user/ajedrez/raw/seleccionados/\"\n",
    "\n",
    "# Ruta donde se guardarán los resultados individuales en HDFS\n",
    "ruta_salida_hdfs = \"hdfs:///user/ajedrez/analizados_grupo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02071c8-e040-424e-881f-5f078ddb69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_pgn(pgn_path: str, stockfish_path: str = \"stockfish.exe\"):\n",
    "    log_path = \"errores_pgn.log\"\n",
    "    central_squares = {\"d4\", \"e4\", \"d5\", \"e5\"}\n",
    "    \n",
    "    piece_value = {\"p\": 1, \"n\": 3, \"b\": 3, \"r\": 5, \"q\": 9, \"k\": 0}\n",
    "    stockfish = Stockfish(path=stockfish_path)\n",
    "\n",
    "    players = defaultdict(lambda: {\n",
    "        \"fide_id\": None,\n",
    "        \"elo\": [],\n",
    "        \"resultados\": [],\n",
    "        \"partidas\": 0,\n",
    "        \"movimientos_total\": [],\n",
    "        \"enroque\": [],\n",
    "        \"intercambio_piezas\": [],\n",
    "        \"sacrificios\": [],\n",
    "        \"mov_peones\": [],\n",
    "        \"mov_centrales\": [],\n",
    "        \"cod_eco\": [],\n",
    "        \"evaluacion_cp\": [],\n",
    "        \"evaluacion_cp_apertura\": [],\n",
    "        \"evaluacion_cp_mediojuego\": [],\n",
    "        \"evaluacion_cp_final\": [],\n",
    "        \"errores_graves\": [],\n",
    "        \"errores\": [],\n",
    "        \"errores_leves\": [],\n",
    "        \"errores_graves_apertura\": [],\n",
    "        \"errores_graves_mediojuego\": [],\n",
    "        \"errores_graves_final\": [],\n",
    "        \"errores_apertura\": [],\n",
    "        \"errores_mediojuego\": [],\n",
    "        \"errores_final\": [],\n",
    "        \"errores_leves_apertura\": [],\n",
    "        \"errores_leves_mediojuego\": [],\n",
    "        \"errores_leves_final\": [],\n",
    "        \"evento\": [],\n",
    "        \"lugar\": [],\n",
    "        \"pgn\": [],\n",
    "        \"san\": [],\n",
    "        \"fechas\": []\n",
    "    })\n",
    "\n",
    "    jugadores_objetivo = set()\n",
    "    with open(pgn_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "            jugadores_objetivo.add(game.headers.get(\"White\", \"Unknown\"))\n",
    "            jugadores_objetivo.add(game.headers.get(\"Black\", \"Unknown\"))\n",
    "    jugadores_objetivo = {j for j in jugadores_objetivo if j not in {\"?\", \"Unknown\", \"\"}}\n",
    "\n",
    "    with open(pgn_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        total_games = sum(1 for _ in iter(lambda: chess.pgn.read_game(f), None))\n",
    "\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(f\"Registro de errores - {datetime.datetime.now()}\\n\\n\")\n",
    "\n",
    "    with open(pgn_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for i in tqdm(range(total_games), desc=\"Analizando partidas\"):\n",
    "            try:\n",
    "                game = chess.pgn.read_game(f)\n",
    "                if game is None:\n",
    "                    break\n",
    "\n",
    "                white = game.headers.get(\"White\", \"Unknown\")\n",
    "                black = game.headers.get(\"Black\", \"Unknown\")\n",
    "                white_fide = game.headers.get(\"WhiteFideId\", \"None\")\n",
    "                black_fide = game.headers.get(\"BlackFideId\", \"None\")\n",
    "                white_elo = int(game.headers.get(\"WhiteElo\", \"0\"))\n",
    "                black_elo = int(game.headers.get(\"BlackElo\", \"0\"))\n",
    "                resultado_raw = game.headers.get(\"Result\", \"*\")\n",
    "\n",
    "                exporter = chess.pgn.StringExporter(headers=True, variations=False, comments=False)\n",
    "                pgn_str = game.accept(exporter)\n",
    "\n",
    "                board = game.board()\n",
    "                jugadas_san = []\n",
    "                for move in game.mainline_moves():\n",
    "                    jugadas_san.append(board.san(move))\n",
    "                    board.push(move)\n",
    "\n",
    "                resultado_white, resultado_black = {\n",
    "                    \"1-0\": (1.0, 0.0),\n",
    "                    \"0-1\": (0.0, 1.0),\n",
    "                    \"1/2-1/2\": (0.5, 0.5)\n",
    "                }.get(resultado_raw, (None, None))\n",
    "\n",
    "                if white not in jugadores_objetivo and black not in jugadores_objetivo:\n",
    "                    continue\n",
    "\n",
    "                eco = game.headers.get(\"ECO\", \"None\")\n",
    "                fecha_str = game.headers.get(\"Date\", None)\n",
    "                try:\n",
    "                    fecha = datetime.datetime.strptime(fecha_str, \"%Y.%m.%d\").date()\n",
    "                except:\n",
    "                    fecha = None\n",
    "\n",
    "                game_counted = {\"W\": False, \"B\": False}\n",
    "                board = game.board()\n",
    "                move_number = 0\n",
    "                moves_list = []\n",
    "                jugador_stats_temporales = {\"W\": defaultdict(int), \"B\": defaultdict(int)}\n",
    "                contador_jugadas_por_jugador = {\"W\": 0, \"B\": 0}\n",
    "                evaluaciones_por_fase = {\"apertura\": [], \"mediojuego\": [], \"final\": [], \"total\": []}\n",
    "\n",
    "                for move in game.mainline_moves():\n",
    "                    move_number += 1\n",
    "                    current_player = white if board.turn else black\n",
    "                    color_tag = \"W\" if board.turn else \"B\"\n",
    "\n",
    "                    if current_player not in jugadores_objetivo:\n",
    "                        board.push(move)\n",
    "                        continue\n",
    "\n",
    "                    contador_jugadas_por_jugador[color_tag] += 1\n",
    "\n",
    "                    key = (current_player, color_tag)\n",
    "                    stats = players[key]\n",
    "                    stats_temp = jugador_stats_temporales[color_tag]\n",
    "\n",
    "                    if not game_counted[color_tag]:\n",
    "                        stats[\"partidas\"] += 1\n",
    "                        stats[\"cod_eco\"].append(eco)\n",
    "                        stats[\"fide_id\"] = white_fide if color_tag == \"W\" else black_fide\n",
    "                        stats[\"elo\"].append(white_elo if color_tag == \"W\" else black_elo)\n",
    "                        stats[\"resultados\"].append(resultado_white if color_tag == \"W\" else resultado_black)\n",
    "                        if fecha:\n",
    "                            stats[\"fechas\"].append(fecha)\n",
    "                        stats[\"evento\"].append(game.headers.get(\"Event\", \"\"))\n",
    "                        stats[\"lugar\"].append(game.headers.get(\"Site\", \"\"))\n",
    "                        stats[\"pgn\"].append(pgn_str)\n",
    "                        stats[\"san\"].append(jugadas_san)\n",
    "\n",
    "                    game_counted[color_tag] = True\n",
    "                    uci = move.uci()\n",
    "                    moves_list.append(uci)\n",
    "\n",
    "                    try:\n",
    "                        stockfish.set_position(moves_list[:-1])\n",
    "                        eval_before = stockfish.get_evaluation()[\"value\"] or 0\n",
    "                        stockfish.set_position(moves_list)\n",
    "                        eval_after = stockfish.get_evaluation()[\"value\"] or 0\n",
    "                    except Exception as sf_error:\n",
    "                        raise RuntimeError(f\"Stockfish error en jugada {uci}: {sf_error}\")\n",
    "\n",
    "                    loss = abs(eval_before - eval_after)\n",
    "                    fase = \"apertura\" if move_number <= 20 else \"mediojuego\" if move_number <= 60 else \"final\"\n",
    "                    eval_abs = abs(eval_after)\n",
    "                    evaluaciones_por_fase[fase].append(eval_abs)\n",
    "                    evaluaciones_por_fase[\"total\"].append(eval_abs)\n",
    "\n",
    "                    piece = board.piece_at(move.from_square)\n",
    "                    if not board.is_legal(move):\n",
    "                        raise ValueError(f\"Movimiento ilegal: {uci} en {board.fen()}\")\n",
    "\n",
    "                    san = board.san(move)\n",
    "                    board.push(move)\n",
    "\n",
    "                    stats_temp[\"movimientos_total\"] += 1\n",
    "\n",
    "                    if san in [\"O-O\", \"O-O-O\"] and \"enroque\" not in stats_temp:\n",
    "                        stats_temp[\"enroque\"] = contador_jugadas_por_jugador[color_tag]\n",
    "\n",
    "                    if \"x\" in san:\n",
    "                        stats_temp[\"intercambio_piezas\"] += 1\n",
    "                        capturada = board.piece_at(move.to_square)\n",
    "                        if capturada:\n",
    "                            atacante = piece_value[piece.symbol().lower()]\n",
    "                            capturada_valor = piece_value[capturada.symbol().lower()]\n",
    "                            if atacante > capturada_valor and loss < 150:\n",
    "                                stats_temp[\"sacrificios\"] += 1\n",
    "\n",
    "                    if piece and piece.symbol().lower() == \"p\":\n",
    "                        stats_temp[\"mov_peones\"] += 1\n",
    "\n",
    "                    if chess.square_name(move.to_square) in central_squares:\n",
    "                        stats_temp[\"mov_centrales\"] += 1\n",
    "\n",
    "                    if loss > 300:\n",
    "                        stats_temp[\"errores_graves\"] += 1\n",
    "                        stats_temp[f\"blunders_{fase}\"] += 1\n",
    "                    elif loss > 100:\n",
    "                        stats_temp[\"errores\"] += 1\n",
    "                        stats_temp[f\"errores_{fase}\"] += 1\n",
    "                    elif loss > 50:\n",
    "                        stats_temp[\"errores_leves\"] += 1\n",
    "                        stats_temp[f\"imprecisiones_{fase}\"] += 1\n",
    "\n",
    "                for color_tag, jugador in [(\"W\", white), (\"B\", black)]:\n",
    "                    if jugador in jugadores_objetivo:\n",
    "                        stats = players[(jugador, color_tag)]\n",
    "                        temp = jugador_stats_temporales[color_tag]\n",
    "                        stats[\"movimientos_total\"].append(temp[\"movimientos_total\"])\n",
    "                        stats[\"mov_peones\"].append(temp[\"mov_peones\"])\n",
    "                        stats[\"mov_centrales\"].append(temp[\"mov_centrales\"])\n",
    "                        stats[\"intercambio_piezas\"].append(temp[\"intercambio_piezas\"])\n",
    "                        stats[\"sacrificios\"].append(temp[\"sacrificios\"])\n",
    "                        stats[\"enroque\"].append(temp[\"enroque\"] if \"enroque\" in temp else 0)\n",
    "\n",
    "                        for fase_eval in [\"total\", \"apertura\", \"mediojuego\", \"final\"]:\n",
    "                            lista = evaluaciones_por_fase[fase_eval]\n",
    "                            campo = f\"evaluacion_cp\" if fase_eval == \"total\" else f\"evaluacion_cp_{fase_eval}\"\n",
    "                            stats[campo].append(statistics.mean(lista) if lista else None)\n",
    "\n",
    "                        errores_map = {\n",
    "                            \"errores_graves\": \"errores_graves\",\n",
    "                            \"errores\": \"errores\",\n",
    "                            \"errores_leves\": \"errores_leves\",\n",
    "                            \"errores_graves_apertura\": \"blunders_apertura\",\n",
    "                            \"errores_graves_mediojuego\": \"blunders_mediojuego\",\n",
    "                            \"errores_graves_final\": \"blunders_final\",\n",
    "                            \"errores_apertura\": \"errores_apertura\",\n",
    "                            \"errores_mediojuego\": \"errores_mediojuego\",\n",
    "                            \"errores_final\": \"errores_final\",\n",
    "                            \"errores_leves_apertura\": \"imprecisiones_apertura\",\n",
    "                            \"errores_leves_mediojuego\": \"imprecisiones_mediojuego\",\n",
    "                            \"errores_leves_final\": \"imprecisiones_final\"\n",
    "                        }\n",
    "\n",
    "                        for campo_destino, campo_temp in errores_map.items():\n",
    "                            valor = temp.get(campo_temp, 0)\n",
    "                            stats[campo_destino].append(valor)\n",
    "\n",
    "            except Exception as e:\n",
    "                msg = f\" Error en partida #{i+1} ({white} vs {black}): {e}\"\n",
    "                print(\"\\n\" + msg)\n",
    "                with open(log_path, \"a\", encoding=\"utf-8\") as log_file:\n",
    "                    log_file.write(msg + \"\\n\")\n",
    "\n",
    "    filas = []\n",
    "    for (nombre, color), datos in players.items():\n",
    "        for i in range(datos[\"partidas\"]):\n",
    "            fila = {\"jugador\": nombre, \"color\": color, \"fide_id\": datos.get(\"fide_id\", \"\")}\n",
    "            for campo, valores in datos.items():\n",
    "                if isinstance(valores, list) and len(valores) > i:\n",
    "                    fila[campo] = valores[i]\n",
    "            filas.append(fila)\n",
    "\n",
    "    df_partidas = pd.DataFrame(filas)\n",
    "    df_partidas[\"fechas\"] = pd.to_datetime(df_partidas[\"fechas\"], errors=\"coerce\")\n",
    "    df_partidas = df_partidas.fillna(np.nan)\n",
    "\n",
    "    nombre_archivo = f\"analisis_{os.path.splitext(os.path.basename(pgn_path))[0]}.parquet\"\n",
    "    df_partidas.to_parquet(nombre_archivo, engine=\"pyarrow\", coerce_timestamps=\"ms\")\n",
    "    return nombre_archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfdc249f-d0f2-4933-aeac-2b3914792613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import datetime\n",
    "import statistics\n",
    "import chess.pgn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from stockfish import Stockfish\n",
    "\n",
    "def procesar_y_guardar_en_hdfs(archivo):\n",
    "    from pathlib import Path\n",
    "    \n",
    "    nombre_archivo = Path(archivo[0]).stem\n",
    "    contenido_pgn = archivo[1]\n",
    "    \n",
    "    # Guardar temporalmente en disco local\n",
    "    ruta_temp = f\"/tmp/{nombre_archivo}.pgn\"\n",
    "    with open(ruta_temp, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(contenido_pgn)\n",
    "\n",
    "    try:\n",
    "        salida = analizar_pgn(\n",
    "            pgn_path=ruta_temp,\n",
    "            stockfish_path=\"stockfish\",\n",
    "            log_errores=False,\n",
    "            mostrar_progreso=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        parquet_local = Path(salida)\n",
    "        parquet_hdfs = f\"{ruta_salida_hdfs}analisis_{nombre_archivo}.parquet\"\n",
    "        \n",
    "        # Subir al HDFS (sobrescribe si existe)\n",
    "        os.system(f\"hdfs dfs -put -f {parquet_local} {parquet_hdfs}\")\n",
    "        print(f\"Subido a HDFS: {parquet_hdfs}\")\n",
    "        return parquet_hdfs\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error en archivo {nombre_archivo}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40a6993-62fd-497b-bb99-0914edc66cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Archivos .parquet generados en HDFS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Leer archivos desde HDFS como RDD [(ruta, contenido), ...]\n",
    "rdd_archivos = spark.sparkContext.wholeTextFiles(ruta_entrada_hdfs)\n",
    "\n",
    "# Analizar y guardar resultados por archivo en paralelo en el clúster\n",
    "resultados = rdd_archivos.map(procesar_y_guardar_en_hdfs).collect()\n",
    "\n",
    "# Mostrar los archivos subidos\n",
    "print(\"\\n Archivos .parquet generados en HDFS:\")\n",
    "for archivo in resultados:\n",
    "    if archivo:\n",
    "        print(\"   -\", archivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19064dfe-e326-494f-8deb-68305e9c7737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1df9817-6bbd-46d9-ada1-761d5c9bbc02",
   "metadata": {},
   "source": [
    "## 10. Entrenamiento de la Red Neuronal Convolucional (CNN) - yarn (PRUEBAS / NO FUNCIONA)\n",
    "\n",
    "Al parecer no es aconsejable lanzar entrenamientos distribuidos desde Jupyter Notebook, se recomienda hacer un script y lanzarlo desde el bash (de spark-client dentro de /notebooks/).\n",
    "\n",
    "Creamos el *train_model_blancas.py* para blancas (el de negras será análogo)\n",
    "\n",
    "He tenido que instalar en los datanodes 1 y 2:\n",
    "`pip install pandas tensorflow sci-kitlearn tensorflowonspark pyarrow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9e3c73d-0f23-4d92-b688-18c4d79d70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_model_blancas.py\", \"w\") as f:\n",
    "    f.write(\"\"\"import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflowonspark import TFCluster, TFNode\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"2\"\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"1\"\n",
    "\n",
    "# Función que define la arquitectura del modelo\n",
    "def model_fn(num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(8, 8, 12)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Función principal que ejecuta cada nodo\n",
    "def main_fun(args, ctx):\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    \n",
    "    # Leer el parquet desde HDFS\n",
    "    df_spark = spark.read.parquet(args[\"data_path\"])\n",
    "    df = df_spark.toPandas()  # Convertir a pandas DataFrame\n",
    "\n",
    "    X = np.array(df[\"features\"].tolist()).reshape(-1, 8, 8, 12)\n",
    "    y = df[\"label\"].astype(np.int32).values\n",
    "\n",
    "    num_classes = len(np.unique(y))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "    model = model_fn(num_classes)\n",
    "    model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), batch_size=32)\n",
    "\n",
    "    if ctx.job_name == \"chief\":\n",
    "        model.save(args[\"model_path\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName(\"TFoS-CNN-Blancas\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "\n",
    "    # Ruta al HDFS\n",
    "    args = {\n",
    "        \"data_path\": \"hdfs:///user/ajedrez/datos_cnn/blancas/fen_jugadas.parquet\",\n",
    "        \"model_path\": \"/notebooks/datos_cnn/modelo_blancas\"\n",
    "    }\n",
    "\n",
    "    import socket\n",
    "    args[\"host\"] = socket.gethostbyname(socket.gethostname())\n",
    "\n",
    "    cluster = TFCluster.run(\n",
    "        sc, main_fun, args,\n",
    "        num_executors=2,\n",
    "        num_ps=1,\n",
    "        input_mode=TFCluster.InputMode.TENSORFLOW,\n",
    "        master_node=\"chief\",\n",
    "        log_dir=\"/tmp/tf_logs\"\n",
    "    )\n",
    "\n",
    "    cluster.shutdown()\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b4830-8c39-4d47-838c-d49e287efdfb",
   "metadata": {},
   "source": [
    "Lo ejecutamos con:\n",
    "\n",
    "`nohup spark-submit   --master yarn   --conf spark.executor.instances=2   --conf spark.executor.memory=2g   --conf spark.executor.cores=2   --conf spark.driver.memory=2g   --conf spark.yarn.am.memory=512m   train_model_blancas.py > entrenamiento_blancas.log 2>&1 &`\n",
    "\n",
    "y para ver la salida:\n",
    "\n",
    "`tail -f entrenamiento_blancas.log`\n",
    "\n",
    "No logro que funcione ... en localhost:8088 veo que están los procesos pero los que están esperando nunca arrancan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e000d-364b-4168-97f2-ec547878f2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed2b4c-f7d2-4b90-8a0b-d931c25b3e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff35d93b-94e3-421a-94d8-d6993bba5a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b310df1-f86a-41e6-a71f-5634ae917f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4447e-4d8f-44c1-84f9-96ba2de9e49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
